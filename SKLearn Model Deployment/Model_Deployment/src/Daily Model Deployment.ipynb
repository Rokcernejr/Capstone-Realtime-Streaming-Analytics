{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Model Deployment\n",
    "\n",
    "1. Load Model from S3\n",
    "2. Query past 10 mintues of data from MongoDB\n",
    "3. Build Features\n",
    "4. Make Predictions\n",
    "5. Log predictions to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Initialize ###################\n",
    "\n",
    "# Basics\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import boto3\n",
    "import io\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from datetime import date, datetime, timedelta\n",
    "import subprocess\n",
    "\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "import spacy\n",
    "spacy.load('en')\n",
    "from nltk.corpus import stopwords\n",
    "import preprocessor as p\n",
    "\n",
    "# Model Infrastructure\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.pipeline import make_pipeline, Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn import metrics\n",
    "import dill as pickle\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Database Setup\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect\n",
    "from sqlalchemy import MetaData\n",
    "from sqlalchemy import Table\n",
    "from sqlalchemy import Column\n",
    "from sqlalchemy import Integer, String, DateTime, Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily_Model_predictions Table does not exist\n",
      "Daily_Model_predictions Table being created....\n"
     ]
    }
   ],
   "source": [
    "########## Database Setup #################\n",
    "User = os.environ['DB_USER']\n",
    "password = os.environ['DB_PWD']\n",
    "dbname = os.environ['DB_NAME']\n",
    "IP = os.environ['IP']\n",
    "\n",
    "engine = create_engine('mysql+mysqlconnector://{}:{}@{}:3306/{}'.format(User,\n",
    "                                                                        password, IP, dbname), echo=False)\n",
    "conn = engine.connect()\n",
    "\n",
    "# Check to see if the tables are created and if not, create them\n",
    "meta = MetaData(engine)\n",
    "\n",
    "# Create prediction table\n",
    "if not engine.dialect.has_table(engine, 'daily_model_predictions'):\n",
    "    print('Daily_Model_predictions Table does not exist')\n",
    "    print('Daily_Model_predictions Table being created....')\n",
    "    # Time, Source, Current Count, Count Diff\n",
    "    t1 = Table('daily_model_predictions', meta,\n",
    "               Column('run_time', DateTime, default=datetime.utcnow),\n",
    "               Column('model_name', String(30)),\n",
    "               Column('model_version_number', Integer),\n",
    "               Column('Company', String(30)),\n",
    "               Column('Prediction', Integer))\n",
    "    t1.create()\n",
    "else:\n",
    "    print('Model_predictions Table Exists')\n",
    "\n",
    "# Create table object\n",
    "meta = MetaData(engine, reflect=True)\n",
    "daily_model_predictions_table = meta.tables['daily_model_predictions']    \n",
    "\n",
    "# Write Function\n",
    "def database_log(name, version_number, company, prediction):\n",
    "    #Need to log these items to a database.\n",
    "        \n",
    "    ins = daily_model_predictions_table.insert().values(\n",
    "            run_time = datetime.now(),\n",
    "            model_name = name,\n",
    "            model_version_number = version_number,\n",
    "            Company = company,\n",
    "            Prediction = prediction\n",
    "               )\n",
    "    conn.execute(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['aws', 's3', 'cp', 's3://brandyn-twitter-sentiment-analysis/Models/Daily_Stock_Prediction_latest.pk', './Models'], returncode=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the Model\n",
    "subprocess.run(['aws', 's3','cp','s3://brandyn-twitter-sentiment-analysis/Models/Daily_Stock_Prediction_latest.pk','./Models'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "### Validate Pickle ###\n",
    "filename = 'Daily_Stock_Prediction_latest.pk'\n",
    "\n",
    "with open('./Models/'+filename, 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Bring In Data #######################\n",
    "#Setup Mongo and create the database and collection\n",
    "User = os.environ['MONGODB_USER']\n",
    "password = os.environ['MONGODB_PASS']\n",
    "IP = os.environ['IP']\n",
    "\n",
    "client = MongoClient(IP, username=User, password=password)\n",
    "db = client['stock_tweets']\n",
    "\n",
    "#Grab references\n",
    "twitter_coll_reference = db.twitter\n",
    "iex_coll_reference = db.iex\n",
    "\n",
    "# Create Time bound\n",
    "ten_min_bound =  pd.to_datetime(datetime.utcnow() - timedelta(hours = 24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Build Twitter Data Frames #####################\n",
    "\n",
    "\n",
    "# Create Data Frame from Mongo DB\n",
    "twitter_data = pd.DataFrame(list(twitter_coll_reference.find()))\n",
    "\n",
    "# Take a subset of the data, dont need all points to convert and this greatly speeds up\n",
    "twitter_data_subset = twitter_data.tail(400)\n",
    "\n",
    "# Need to convert the created_at to a time stamp and set to index\n",
    "twitter_data_subset['created_at'] = pd.to_datetime(twitter_data_subset['created_at'])\n",
    "twitter_data_subset.index=twitter_data_subset['created_at']\n",
    "\n",
    "# Create time bounded dataframe\n",
    "twitter_data = twitter_data_subset[twitter_data_subset['created_at'] >= ten_min_bound]\n",
    "\n",
    "# Delimited the Company List into separate rows\n",
    "delimited_twitter_data=[]\n",
    "\n",
    "for item in twitter_data.itertuples():\n",
    "    #twitter_dict={}\n",
    "    for company in item[1]:\n",
    "        twitter_dict={}\n",
    "        twitter_dict['created_at']=item[0]\n",
    "        twitter_dict['company']=company\n",
    "        twitter_dict['text']=item[11]\n",
    "        twitter_dict['user_followers_count']=item[12]\n",
    "        twitter_dict['user_name']=item[13]\n",
    "        twitter_dict['user_statuses_count']=item[15]\n",
    "        delimited_twitter_data.append(twitter_dict)\n",
    "\n",
    "delimited_twitter_df = pd.DataFrame(delimited_twitter_data) \n",
    "delimited_twitter_df.set_index('created_at', inplace=True)\n",
    "\n",
    "# Create hourly data frame\n",
    "twitter_delimited_daily = delimited_twitter_df.groupby([pd.Grouper(freq=\"D\"), 'company']).count()['text'].to_frame()\n",
    "twitter_delimited_daily.columns = ['Number_of_Tweets']\n",
    "\n",
    "# Concatenate the text with a space to not combine words.\n",
    "twitter_delimited_daily['text']=delimited_twitter_df.groupby([pd.Grouper(freq=\"D\"), 'company'])['text'].apply(lambda x: ' '.join(x))\n",
    "# Number of Users\n",
    "twitter_delimited_daily['Number_of_Users'] = delimited_twitter_df.groupby([pd.Grouper(freq=\"D\"), 'company'])['user_name'].nunique()\n",
    "\n",
    "# Rename Index\n",
    "twitter_delimited_daily = twitter_delimited_daily.reindex(twitter_delimited_daily.index.rename(['Time', 'Company']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Number_of_Tweets</th>\n",
       "      <th>text</th>\n",
       "      <th>Number_of_Users</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th>Company</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2018-05-18</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>12</td>\n",
       "      <td>ThinkScript Tutorial: Using Custom Scripts In ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>23</td>\n",
       "      <td>@JaviFusco When it hits 2718 they gonna bail l...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Number_of_Tweets  \\\n",
       "Time       Company                     \n",
       "2018-05-18 AAPL                   12   \n",
       "           AMZN                   23   \n",
       "\n",
       "                                                                 text  \\\n",
       "Time       Company                                                      \n",
       "2018-05-18 AAPL     ThinkScript Tutorial: Using Custom Scripts In ...   \n",
       "           AMZN     @JaviFusco When it hits 2718 they gonna bail l...   \n",
       "\n",
       "                    Number_of_Users  \n",
       "Time       Company                   \n",
       "2018-05-18 AAPL                  10  \n",
       "           AMZN                  22  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_delimited_daily.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
