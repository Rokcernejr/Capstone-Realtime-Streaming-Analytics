{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Model Deployment\n",
    "\n",
    "1. Load Model from S3\n",
    "2. Query past 10 mintues of data from MongoDB\n",
    "3. Build Features\n",
    "4. Make Predictions\n",
    "5. Log predictions to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Initialize ###################\n",
    "\n",
    "# Basics\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import boto3\n",
    "import io\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from datetime import date, datetime, timedelta\n",
    "import subprocess\n",
    "\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "import spacy\n",
    "spacy.load('en')\n",
    "from nltk.corpus import stopwords\n",
    "import preprocessor as p\n",
    "\n",
    "# Model Infrastructure\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.pipeline import make_pipeline, Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn import metrics\n",
    "import dill as pickle\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Database Setup\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect\n",
    "from sqlalchemy import MetaData\n",
    "from sqlalchemy import Table\n",
    "from sqlalchemy import Column\n",
    "from sqlalchemy import Integer, String, DateTime, Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily_Model_predictions Table Exists\n"
     ]
    }
   ],
   "source": [
    "########## Database Setup #################\n",
    "User = os.environ['DB_USER']\n",
    "password = os.environ['DB_PWD']\n",
    "dbname = os.environ['DB_NAME']\n",
    "IP = os.environ['IP']\n",
    "\n",
    "engine = create_engine('mysql+mysqlconnector://{}:{}@{}:3306/{}'.format(User,\n",
    "                                                                        password, IP, dbname), echo=False)\n",
    "conn = engine.connect()\n",
    "\n",
    "# Check to see if the tables are created and if not, create them\n",
    "meta = MetaData(engine)\n",
    "\n",
    "# Create prediction table\n",
    "if not engine.dialect.has_table(engine, 'daily_model_predictions'):\n",
    "    print('Daily_Model_predictions Table does not exist')\n",
    "    print('Daily_Model_predictions Table being created....')\n",
    "    # Time, Source, Current Count, Count Diff\n",
    "    t1 = Table('daily_model_predictions', meta,\n",
    "               Column('run_time', DateTime, default=datetime.utcnow),\n",
    "               Column('model_name', String(30)),\n",
    "               Column('model_version_number', Integer),\n",
    "               Column('Company', String(30)),\n",
    "               Column('Prediction', Integer))\n",
    "    t1.create()\n",
    "else:\n",
    "    print('Daily_Model_predictions Table Exists')\n",
    "\n",
    "# Create table object\n",
    "meta = MetaData(engine, reflect=True)\n",
    "daily_model_predictions_table = meta.tables['daily_model_predictions']    \n",
    "\n",
    "# Write Function\n",
    "def database_log(name, version_number, company, prediction):\n",
    "    #Need to log these items to a database.\n",
    "        \n",
    "    ins = daily_model_predictions_table.insert().values(\n",
    "            run_time = datetime.now(),\n",
    "            model_name = name,\n",
    "            model_version_number = version_number,\n",
    "            Company = company,\n",
    "            Prediction = prediction\n",
    "               )\n",
    "    conn.execute(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['aws', 's3', 'cp', 's3://brandyn-twitter-sentiment-analysis/Models/Daily_Stock_Prediction_latest.pk', './Models'], returncode=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the Model\n",
    "subprocess.run(['aws', 's3','cp','s3://brandyn-twitter-sentiment-analysis/Models/Daily_Stock_Prediction_latest.pk','./Models'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "### Validate Pickle ###\n",
    "filename = 'Daily_Stock_Prediction_latest.pk'\n",
    "\n",
    "with open('./Models/'+filename, 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Bring In Data #######################\n",
    "#Setup Mongo and create the database and collection\n",
    "User = os.environ['MONGODB_USER']\n",
    "password = os.environ['MONGODB_PASS']\n",
    "IP = os.environ['IP']\n",
    "\n",
    "client = MongoClient(IP, username=User, password=password)\n",
    "db = client['stock_tweets']\n",
    "\n",
    "#Grab references\n",
    "twitter_coll_reference = db.twitter\n",
    "iex_coll_reference = db.iex\n",
    "\n",
    "# Create Time bound\n",
    "ten_min_bound =  pd.to_datetime(datetime.utcnow() - timedelta(hours = 48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Build Twitter Data Frames #####################\n",
    "\n",
    "def get_twitter_data():\n",
    "    # Create Data Frame from Mongo DB\n",
    "    twitter_data = pd.DataFrame(list(twitter_coll_reference.find()))\n",
    "\n",
    "    # Take a subset of the data, dont need all points to convert and this greatly speeds up\n",
    "    twitter_data_subset = twitter_data.tail(400)\n",
    "\n",
    "    # Need to convert the created_at to a time stamp and set to index\n",
    "    twitter_data_subset['created_at'] = pd.to_datetime(twitter_data_subset['created_at'])\n",
    "    twitter_data_subset.index=twitter_data_subset['created_at']\n",
    "\n",
    "    # Create time bounded dataframe\n",
    "    twitter_data = twitter_data_subset[twitter_data_subset['created_at'] >= ten_min_bound]\n",
    "\n",
    "    # Delimited the Company List into separate rows\n",
    "    delimited_twitter_data=[]\n",
    "\n",
    "    for item in twitter_data.itertuples():\n",
    "        #twitter_dict={}\n",
    "        for company in item[1]:\n",
    "            twitter_dict={}\n",
    "            twitter_dict['created_at']=item[0]\n",
    "            twitter_dict['company']=company\n",
    "            twitter_dict['text']=item[11]\n",
    "            twitter_dict['user_followers_count']=item[12]\n",
    "            twitter_dict['user_name']=item[13]\n",
    "            twitter_dict['user_statuses_count']=item[15]\n",
    "            delimited_twitter_data.append(twitter_dict)\n",
    "\n",
    "    delimited_twitter_df = pd.DataFrame(delimited_twitter_data) \n",
    "    delimited_twitter_df.set_index('created_at', inplace=True)\n",
    "\n",
    "    # Create hourly data frame\n",
    "    twitter_delimited_daily = delimited_twitter_df.groupby([pd.Grouper(freq=\"D\"), 'company']).count()['text'].to_frame()\n",
    "    twitter_delimited_daily.columns = ['Number_of_Tweets']\n",
    "\n",
    "    # Concatenate the text with a space to not combine words.\n",
    "    twitter_delimited_daily['text']=delimited_twitter_df.groupby([pd.Grouper(freq=\"D\"), 'company'])['text'].apply(lambda x: ' '.join(x))\n",
    "    # Number of Users\n",
    "    twitter_delimited_daily['Number_of_Users'] = delimited_twitter_df.groupby([pd.Grouper(freq=\"D\"), 'company'])['user_name'].nunique()\n",
    "\n",
    "    # Rename Index\n",
    "    twitter_delimited_daily = twitter_delimited_daily.reindex(twitter_delimited_daily.index.rename(['Time', 'Company']))\n",
    "    return twitter_delimited_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Build Stock Data Frames ###########################\n",
    "\n",
    "def get_stock_data():\n",
    "    stock_data = pd.DataFrame(list(iex_coll_reference.find()))\n",
    "    \n",
    "    # Take a subset of the data, dont need all points to convert and this greatly speeds up\n",
    "    stock_data_subset = stock_data.tail(400)\n",
    "    \n",
    "    # Need to convert the created_at to a time stamp\n",
    "    stock_data_subset['latestUpdate'] = pd.to_datetime(stock_data_subset['latestUpdate'])\n",
    "    stock_data_subset.index=stock_data_subset['latestUpdate']\n",
    "    \n",
    "    # Create time bounded dataframe\n",
    "    stock_data = stock_data_subset[stock_data_subset['latestUpdate'] >= ten_min_bound]\n",
    "    \n",
    "    # Create delimited dataframe\n",
    "    stock_delimited_daily = stock_data.groupby([pd.Grouper(freq=\"D\"), 'Ticker'])['latestVolume'].mean().to_frame()\n",
    "    stock_delimited_daily.columns = ['Mean_Volume']\n",
    "    \n",
    "    # Rename the Index\n",
    "    stock_delimited_daily = stock_delimited_daily.reindex(stock_delimited_daily.index.rename(['Time', 'Company']))\n",
    "    return stock_delimited_daily\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Company</th>\n",
       "      <th>Number_of_Tweets</th>\n",
       "      <th>text</th>\n",
       "      <th>Number_of_Users</th>\n",
       "      <th>Mean_Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>31</td>\n",
       "      <td>Step by Step Dividend Investing: A Beginner's ...</td>\n",
       "      <td>25</td>\n",
       "      <td>1.366410e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>41</td>\n",
       "      <td>Helluvah specific price there.  Four decimal p...</td>\n",
       "      <td>37</td>\n",
       "      <td>1.285560e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>BA</td>\n",
       "      <td>52</td>\n",
       "      <td>5.18.18 Elliott Wave Updates For Momentum: $BA...</td>\n",
       "      <td>43</td>\n",
       "      <td>3.043739e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>BABA</td>\n",
       "      <td>12</td>\n",
       "      <td>5.18.18 Elliott Wave Updates For Momentum: $BA...</td>\n",
       "      <td>12</td>\n",
       "      <td>7.864113e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>BAC</td>\n",
       "      <td>10</td>\n",
       "      <td>#DivestFromWar\\n\\nDivest from\\nBank of America...</td>\n",
       "      <td>9</td>\n",
       "      <td>4.648342e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time Company  Number_of_Tweets  \\\n",
       "0 2018-05-18    AAPL                31   \n",
       "1 2018-05-18    AMZN                41   \n",
       "2 2018-05-18      BA                52   \n",
       "3 2018-05-18    BABA                12   \n",
       "4 2018-05-18     BAC                10   \n",
       "\n",
       "                                                text  Number_of_Users  \\\n",
       "0  Step by Step Dividend Investing: A Beginner's ...               25   \n",
       "1  Helluvah specific price there.  Four decimal p...               37   \n",
       "2  5.18.18 Elliott Wave Updates For Momentum: $BA...               43   \n",
       "3  5.18.18 Elliott Wave Updates For Momentum: $BA...               12   \n",
       "4  #DivestFromWar\\n\\nDivest from\\nBank of America...                9   \n",
       "\n",
       "    Mean_Volume  \n",
       "0  1.366410e+07  \n",
       "1  1.285560e+06  \n",
       "2  3.043739e+06  \n",
       "3  7.864113e+06  \n",
       "4  4.648342e+07  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call Functions\n",
    "twitter_delimited_daily = get_twitter_data()\n",
    "stock_delimited_daily = get_stock_data()\n",
    "\n",
    "# Combine Dataframes\n",
    "daily_df = pd.concat([twitter_delimited_daily, stock_delimited_daily], axis=1, join='inner')\n",
    "\n",
    "# To flatten after combined everything. \n",
    "daily_df.reset_index(inplace=True)\n",
    "daily_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the Tweets\n",
    "p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.MENTION, p.OPT.RESERVED, p.OPT.EMOJI, p.OPT.HASHTAG)\n",
    "def preprocess_tweet(tweet):\n",
    "    return p.clean(tweet)\n",
    "\n",
    "# Clean the tweets, by removing special characters\n",
    "start_time = time.time()\n",
    "daily_df['Clean_text'] = daily_df['text'].apply(lambda x: preprocess_tweet(x))\n",
    "\n",
    "# Split Between Outcome and Features\n",
    "features = daily_df[['Number_of_Tweets', 'Number_of_Users','Mean_Volume','Clean_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lemmatizer using spacy\n",
    "lemmatizer = spacy.lang.en.English()\n",
    "\n",
    "# Define Model\n",
    "lr_model = LogisticRegression(n_jobs=5, penalty='l2', class_weight='balanced', solver='newton-cg', C=10)\n",
    "\n",
    "# Define custom Tokenizer\n",
    "def custom_tokenizer(doc):\n",
    "    tokens = lemmatizer(doc)\n",
    "    return([token.lemma_ for token in tokens if not token.is_punct])\n",
    "\n",
    "# Define Vectorizer\n",
    "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, stop_words='english',\n",
    "                             lowercase=True, use_idf=True, max_df=2,\n",
    "                             min_df=2, norm='l2', smooth_idf=True, ngram_range=(1, 2))\n",
    "\n",
    "\n",
    "\n",
    "# Predictions\n",
    "y = model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df['predictions'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Company</th>\n",
       "      <th>Number_of_Tweets</th>\n",
       "      <th>text</th>\n",
       "      <th>Number_of_Users</th>\n",
       "      <th>Mean_Volume</th>\n",
       "      <th>Clean_text</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>31</td>\n",
       "      <td>Step by Step Dividend Investing: A Beginner's ...</td>\n",
       "      <td>25</td>\n",
       "      <td>1.366410e+07</td>\n",
       "      <td>Step by Step Dividend Investing: A Beginner's ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>41</td>\n",
       "      <td>Helluvah specific price there.  Four decimal p...</td>\n",
       "      <td>37</td>\n",
       "      <td>1.285560e+06</td>\n",
       "      <td>Helluvah specific price there. Four decimal po...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>BA</td>\n",
       "      <td>52</td>\n",
       "      <td>5.18.18 Elliott Wave Updates For Momentum: $BA...</td>\n",
       "      <td>43</td>\n",
       "      <td>3.043739e+06</td>\n",
       "      <td>5.18.18 Elliott Wave Updates For Momentum: $BA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>BABA</td>\n",
       "      <td>12</td>\n",
       "      <td>5.18.18 Elliott Wave Updates For Momentum: $BA...</td>\n",
       "      <td>12</td>\n",
       "      <td>7.864113e+06</td>\n",
       "      <td>5.18.18 Elliott Wave Updates For Momentum: $BA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>BAC</td>\n",
       "      <td>10</td>\n",
       "      <td>#DivestFromWar\\n\\nDivest from\\nBank of America...</td>\n",
       "      <td>9</td>\n",
       "      <td>4.648342e+07</td>\n",
       "      <td>Divest from Bank of America $BAC Citigroup $C ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>C</td>\n",
       "      <td>47</td>\n",
       "      <td>Mastrapasqua Asset Management Upped Its Cisco ...</td>\n",
       "      <td>33</td>\n",
       "      <td>1.297626e+07</td>\n",
       "      <td>Mastrapasqua Asset Management Upped Its Cisco ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>CMCSA</td>\n",
       "      <td>5</td>\n",
       "      <td>Financial Counselors Has Cut By $2.55 Million ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.200967e+07</td>\n",
       "      <td>Financial Counselors Has Cut By $2.55 Million ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>8</td>\n",
       "      <td>Mastrapasqua Asset Management Upped Its Cisco ...</td>\n",
       "      <td>7</td>\n",
       "      <td>1.808259e+07</td>\n",
       "      <td>Mastrapasqua Asset Management Upped Its Cisco ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>FB</td>\n",
       "      <td>32</td>\n",
       "      <td>Socially responsible funds dump or rethink Fac...</td>\n",
       "      <td>28</td>\n",
       "      <td>7.895356e+06</td>\n",
       "      <td>Socially responsible funds dump or rethink Fac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>GE</td>\n",
       "      <td>19</td>\n",
       "      <td>@tapenal @OptionsHawk profit going into more $...</td>\n",
       "      <td>12</td>\n",
       "      <td>2.653425e+07</td>\n",
       "      <td>profit going into more $GE . General Electric ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>7</td>\n",
       "      <td>Google gave a stunning demo of Assistant makin...</td>\n",
       "      <td>7</td>\n",
       "      <td>6.558960e+05</td>\n",
       "      <td>Google gave a stunning demo of Assistant makin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>7</td>\n",
       "      <td>Google gave a stunning demo of Assistant makin...</td>\n",
       "      <td>7</td>\n",
       "      <td>8.592819e+05</td>\n",
       "      <td>Google gave a stunning demo of Assistant makin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>HD</td>\n",
       "      <td>9</td>\n",
       "      <td>San Francisco Sentry Investment Group Ca Decre...</td>\n",
       "      <td>7</td>\n",
       "      <td>2.821188e+06</td>\n",
       "      <td>San Francisco Sentry Investment Group Ca Decre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>INTC</td>\n",
       "      <td>8</td>\n",
       "      <td>$INTC Folks still as gung ho about #Intel as t...</td>\n",
       "      <td>8</td>\n",
       "      <td>1.690524e+07</td>\n",
       "      <td>$INTC Folks still as gung ho about as they wer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>JNJ</td>\n",
       "      <td>6</td>\n",
       "      <td>Kornitzer Capital Management Has Cut Its Posit...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.373202e+06</td>\n",
       "      <td>Kornitzer Capital Management Has Cut Its Posit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>JPM</td>\n",
       "      <td>13</td>\n",
       "      <td>Free Options Trading! Join Robinhood and get a...</td>\n",
       "      <td>11</td>\n",
       "      <td>9.280257e+06</td>\n",
       "      <td>Free Options Trading! Join Robinhood and get a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>17</td>\n",
       "      <td>Microsoft $MSFT Share Value Rose While Mastrap...</td>\n",
       "      <td>15</td>\n",
       "      <td>1.170110e+07</td>\n",
       "      <td>Microsoft $MSFT Share Value Rose While Mastrap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>19</td>\n",
       "      <td>As Netflix $NFLX Share Price Rose, Grubman Wea...</td>\n",
       "      <td>17</td>\n",
       "      <td>2.031268e+06</td>\n",
       "      <td>As Netflix $NFLX Share Price Rose, Grubman Wea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>19</td>\n",
       "      <td>RT @OphirGottlieb: AMD, Nvidia shares jump aft...</td>\n",
       "      <td>18</td>\n",
       "      <td>9.208211e+06</td>\n",
       "      <td>: AMD, Nvidia shares jump after Cowen sees soa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>PFE</td>\n",
       "      <td>6</td>\n",
       "      <td>Loomis Sayles &amp;amp; Company LP Increases Stake...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.094394e+07</td>\n",
       "      <td>Loomis Sayles &amp;amp; Company LP Increases Stake...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>94</td>\n",
       "      <td>@eriz35 @MontanaSkeptic1 @AndreiBulu @annerajb...</td>\n",
       "      <td>66</td>\n",
       "      <td>5.273824e+06</td>\n",
       "      <td>The real money to be made in $TSLA wil… RT : C...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>TWTR</td>\n",
       "      <td>15</td>\n",
       "      <td>$TWTR Parkland Survivors React To Texas Shooti...</td>\n",
       "      <td>14</td>\n",
       "      <td>9.041124e+06</td>\n",
       "      <td>$TWTR Parkland Survivors React To Texas Shooti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>UNH</td>\n",
       "      <td>3</td>\n",
       "      <td>UnitedHealth Group $UNH Receives $256.03 Avera...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.387303e+06</td>\n",
       "      <td>UnitedHealth Group $UNH Receives $256.03 Avera...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>V</td>\n",
       "      <td>20</td>\n",
       "      <td>Visa $V Earns Neutral Rating from Analysts at ...</td>\n",
       "      <td>18</td>\n",
       "      <td>4.303888e+06</td>\n",
       "      <td>Visa $V Earns Neutral Rating from Analysts at ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>WFC</td>\n",
       "      <td>8</td>\n",
       "      <td>$WFC 6.2m ago: Wells Fargo &amp;amp; Company Decla...</td>\n",
       "      <td>8</td>\n",
       "      <td>1.658014e+07</td>\n",
       "      <td>$WFC 6.2m ago: Wells Fargo &amp;amp; Company Decla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>XOM</td>\n",
       "      <td>5</td>\n",
       "      <td>As Insperity Com $NSP Stock Value Rose, Clean ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5.903270e+06</td>\n",
       "      <td>As Insperity Com $NSP Stock Value Rose, Clean ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time Company  Number_of_Tweets  \\\n",
       "0  2018-05-18    AAPL                31   \n",
       "1  2018-05-18    AMZN                41   \n",
       "2  2018-05-18      BA                52   \n",
       "3  2018-05-18    BABA                12   \n",
       "4  2018-05-18     BAC                10   \n",
       "5  2018-05-18       C                47   \n",
       "6  2018-05-18   CMCSA                 5   \n",
       "7  2018-05-18    CSCO                 8   \n",
       "8  2018-05-18      FB                32   \n",
       "9  2018-05-18      GE                19   \n",
       "10 2018-05-18    GOOG                 7   \n",
       "11 2018-05-18   GOOGL                 7   \n",
       "12 2018-05-18      HD                 9   \n",
       "13 2018-05-18    INTC                 8   \n",
       "14 2018-05-18     JNJ                 6   \n",
       "15 2018-05-18     JPM                13   \n",
       "16 2018-05-18    MSFT                17   \n",
       "17 2018-05-18    NFLX                19   \n",
       "18 2018-05-18    NVDA                19   \n",
       "19 2018-05-18     PFE                 6   \n",
       "20 2018-05-18    TSLA                94   \n",
       "21 2018-05-18    TWTR                15   \n",
       "22 2018-05-18     UNH                 3   \n",
       "23 2018-05-18       V                20   \n",
       "24 2018-05-18     WFC                 8   \n",
       "25 2018-05-18     XOM                 5   \n",
       "\n",
       "                                                 text  Number_of_Users  \\\n",
       "0   Step by Step Dividend Investing: A Beginner's ...               25   \n",
       "1   Helluvah specific price there.  Four decimal p...               37   \n",
       "2   5.18.18 Elliott Wave Updates For Momentum: $BA...               43   \n",
       "3   5.18.18 Elliott Wave Updates For Momentum: $BA...               12   \n",
       "4   #DivestFromWar\\n\\nDivest from\\nBank of America...                9   \n",
       "5   Mastrapasqua Asset Management Upped Its Cisco ...               33   \n",
       "6   Financial Counselors Has Cut By $2.55 Million ...                5   \n",
       "7   Mastrapasqua Asset Management Upped Its Cisco ...                7   \n",
       "8   Socially responsible funds dump or rethink Fac...               28   \n",
       "9   @tapenal @OptionsHawk profit going into more $...               12   \n",
       "10  Google gave a stunning demo of Assistant makin...                7   \n",
       "11  Google gave a stunning demo of Assistant makin...                7   \n",
       "12  San Francisco Sentry Investment Group Ca Decre...                7   \n",
       "13  $INTC Folks still as gung ho about #Intel as t...                8   \n",
       "14  Kornitzer Capital Management Has Cut Its Posit...                5   \n",
       "15  Free Options Trading! Join Robinhood and get a...               11   \n",
       "16  Microsoft $MSFT Share Value Rose While Mastrap...               15   \n",
       "17  As Netflix $NFLX Share Price Rose, Grubman Wea...               17   \n",
       "18  RT @OphirGottlieb: AMD, Nvidia shares jump aft...               18   \n",
       "19  Loomis Sayles &amp; Company LP Increases Stake...                5   \n",
       "20  @eriz35 @MontanaSkeptic1 @AndreiBulu @annerajb...               66   \n",
       "21  $TWTR Parkland Survivors React To Texas Shooti...               14   \n",
       "22  UnitedHealth Group $UNH Receives $256.03 Avera...                3   \n",
       "23  Visa $V Earns Neutral Rating from Analysts at ...               18   \n",
       "24  $WFC 6.2m ago: Wells Fargo &amp; Company Decla...                8   \n",
       "25  As Insperity Com $NSP Stock Value Rose, Clean ...                5   \n",
       "\n",
       "     Mean_Volume                                         Clean_text  \\\n",
       "0   1.366410e+07  Step by Step Dividend Investing: A Beginner's ...   \n",
       "1   1.285560e+06  Helluvah specific price there. Four decimal po...   \n",
       "2   3.043739e+06  5.18.18 Elliott Wave Updates For Momentum: $BA...   \n",
       "3   7.864113e+06  5.18.18 Elliott Wave Updates For Momentum: $BA...   \n",
       "4   4.648342e+07  Divest from Bank of America $BAC Citigroup $C ...   \n",
       "5   1.297626e+07  Mastrapasqua Asset Management Upped Its Cisco ...   \n",
       "6   1.200967e+07  Financial Counselors Has Cut By $2.55 Million ...   \n",
       "7   1.808259e+07  Mastrapasqua Asset Management Upped Its Cisco ...   \n",
       "8   7.895356e+06  Socially responsible funds dump or rethink Fac...   \n",
       "9   2.653425e+07  profit going into more $GE . General Electric ...   \n",
       "10  6.558960e+05  Google gave a stunning demo of Assistant makin...   \n",
       "11  8.592819e+05  Google gave a stunning demo of Assistant makin...   \n",
       "12  2.821188e+06  San Francisco Sentry Investment Group Ca Decre...   \n",
       "13  1.690524e+07  $INTC Folks still as gung ho about as they wer...   \n",
       "14  3.373202e+06  Kornitzer Capital Management Has Cut Its Posit...   \n",
       "15  9.280257e+06  Free Options Trading! Join Robinhood and get a...   \n",
       "16  1.170110e+07  Microsoft $MSFT Share Value Rose While Mastrap...   \n",
       "17  2.031268e+06  As Netflix $NFLX Share Price Rose, Grubman Wea...   \n",
       "18  9.208211e+06  : AMD, Nvidia shares jump after Cowen sees soa...   \n",
       "19  1.094394e+07  Loomis Sayles &amp; Company LP Increases Stake...   \n",
       "20  5.273824e+06  The real money to be made in $TSLA wil… RT : C...   \n",
       "21  9.041124e+06  $TWTR Parkland Survivors React To Texas Shooti...   \n",
       "22  1.387303e+06  UnitedHealth Group $UNH Receives $256.03 Avera...   \n",
       "23  4.303888e+06  Visa $V Earns Neutral Rating from Analysts at ...   \n",
       "24  1.658014e+07  $WFC 6.2m ago: Wells Fargo &amp; Company Decla...   \n",
       "25  5.903270e+06  As Insperity Com $NSP Stock Value Rose, Clean ...   \n",
       "\n",
       "    predictions  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "5             0  \n",
       "6             1  \n",
       "7             0  \n",
       "8             1  \n",
       "9             0  \n",
       "10            1  \n",
       "11            1  \n",
       "12            1  \n",
       "13            0  \n",
       "14            0  \n",
       "15            0  \n",
       "16            1  \n",
       "17            1  \n",
       "18            0  \n",
       "19            1  \n",
       "20            0  \n",
       "21            1  \n",
       "22            1  \n",
       "23            1  \n",
       "24            0  \n",
       "25            0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
