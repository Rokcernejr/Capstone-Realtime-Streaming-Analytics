{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDIS = redis.Redis(host='data_store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "REDIS.set('my_incrementer', 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDIS.get('IEX_Stock_Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDIS.get('Twitter_Stock_Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Manager needs to do many things. One of which is manage the the company list and populate the data-store\n",
    "companies = {\n",
    "    \"AAPL\":\"Apple\",\n",
    "    \"FB\":\"Facebook\",\n",
    "    \"GOOG\":\"Google\"\n",
    "    }\n",
    "REDIS.set('companies', json.dumps(companies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TEst\n",
    "REDIS.set('test',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(REDIS.get('test')) ==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When setting up the flag, need to setup scheudle for the time, but also need to check if after open time\n",
    "# and before close time, and set the flag to true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tzlocal\n",
      "  Downloading tzlocal-1.5.1.tar.gz\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.6/site-packages (from tzlocal)\n",
      "Building wheels for collected packages: tzlocal\n",
      "  Running setup.py bdist_wheel for tzlocal ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ds/.cache/pip/wheels/7c/a1/5d/0f37ce6eb6eea391bd185f5747429a93519be115d007263bcf\n",
      "Successfully built tzlocal\n",
      "Installing collected packages: tzlocal\n",
      "Successfully installed tzlocal-1.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tzlocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the publish subscribe\n",
    "p = REDIS.pubsub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.subscribe('test-channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the same json dumps as setting the companies.\n",
    "REDIS.publish('test-channel', json.dumps({'event':'test'}))\n",
    "REDIS.publish('test-channel', 'other data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channel': b'test-channel',\n",
       " 'data': b'other data',\n",
       " 'pattern': None,\n",
       " 'type': 'message'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Once publish teh data, can only read the data once. Once its read its gone.\n",
    "#Have to continuously pull off the queue.\n",
    "p.get_message()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Gone\n"
     ]
    }
   ],
   "source": [
    "if p.get_message():\n",
    "    print('Data There')\n",
    "else:\n",
    "    print('Data Gone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-af1c35c84410>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             raise TypeError('the JSON object must be str, bytes or bytearray, '\n\u001b[0;32m--> 348\u001b[0;31m                             'not {!r}'.format(s.__class__.__name__))\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetect_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'surrogatepass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not 'dict'"
     ]
    }
   ],
   "source": [
    "json.loads(p.get_message()).decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Purpose:\n",
    "1. Setup the log table\n",
    "2. Setup the error table\n",
    "3. Setup the company list and set the Redis Value\n",
    "4. Control the Sync schedule (When to set the DataOn variable)\n",
    "5. Subscribe to the error subscription and log errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import redis\n",
    "import json\n",
    "import schedule\n",
    "import time\n",
    "import datetime\n",
    "#from tzlocal import get_localzone\n",
    "\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect\n",
    "from sqlalchemy import MetaData\n",
    "from sqlalchemy import Table\n",
    "from sqlalchemy import Column\n",
    "from sqlalchemy import Integer, String, DateTime\n",
    "\n",
    "#Connect to the DataStore\n",
    "REDIS = redis.Redis(host='data_store')\n",
    "\n",
    "#Create the subscribe\n",
    "event_queue = REDIS.pubsub()\n",
    "#Subscribe to the event queue\n",
    "event_queue.subscribe('event_queue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stream'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check environment variables\n",
    "%env DB_USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Exists\n"
     ]
    }
   ],
   "source": [
    "#Setup Database\n",
    "User = %env DB_USER\n",
    "password = %env DB_PWD\n",
    "dbname = %env DB_NAME\n",
    "\n",
    "\n",
    "engine = create_engine('mysql+mysqlconnector://{}:{}@db:3306/{}'.format(User, password, dbname), echo=False)\n",
    "inspector = inspect(engine)\n",
    "\n",
    "\n",
    "\n",
    "#Create table object\n",
    "meta = MetaData(engine)\n",
    "\n",
    "#Create log table\n",
    "if not engine.dialect.has_table(engine, 'log'):\n",
    "    print('Log Table does not exist')\n",
    "    print('Log Table being created....')\n",
    "    #Time, Source, Current Count, Count Diff\n",
    "    t1 = Table('log', meta,\n",
    "                 Column('log_time', DateTime, default=datetime.datetime.utcnow),\n",
    "                 Column('Source', String(30)),\n",
    "                 Column('Current_Count', Integer),\n",
    "                 Column('Count_Diff', Integer))\n",
    "    t1.create()\n",
    "else:\n",
    "    print('Log Table Exists')\n",
    "\n",
    "#Create event table\n",
    "if not engine.dialect.has_table(engine, 'event'):\n",
    "    print('Event Table does not exist')\n",
    "    print('Event Table being created....')\n",
    "    #Time, Source, Current Count, Count Diff\n",
    "    t1 = Table('event', meta,\n",
    "                 Column('event_time', DateTime, default=datetime.datetime.utcnow),\n",
    "                 Column('Source', String(30)),\n",
    "                 Column('Message', String(8000)))\n",
    "    t1.create()\n",
    "else:\n",
    "    print('Event Table Exists')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x7fd3ada03668>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############ Test insert ##################\n",
    "conn = engine.connect()\n",
    "ins = t1.insert().values(\n",
    "            log_time = datetime.datetime.now(),\n",
    "            Source = 'Test',\n",
    "            Current_Count=42,\n",
    "            Count_Diff=5\n",
    "               )\n",
    "conn.execute(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set up the company list\n",
    "companies = {\n",
    "    \"AAPL\":\"Apple\",\n",
    "    \"FB\":\"Facebook\",\n",
    "    \"GOOG\":\"Google\"\n",
    "    }\n",
    "REDIS.set('companies', json.dumps(companies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup the Data ON Flag and default to 0\n",
    "REDIS.set('Data_On',0)\n",
    "\n",
    "#Create Explicit Data On/Off Functions\n",
    "def DataOn():\n",
    "    REDIS.set('Data_On',1)\n",
    "\n",
    "def DataOff():\n",
    "    REDIS.set('Data_On',0)\n",
    "    \n",
    "global past_twitter_count\n",
    "past_tweet_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Turn on if starts during open times\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "if now.hour >= 14 and now.hour < 21:\n",
    "    if now.hour = 14 and now.minute >= 30:\n",
    "        DataOn()\n",
    "    elif now.hour > 14:\n",
    "        DataOn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Schedules. Time in 24 hour clocks\n",
    "schedule.clear()\n",
    "#Setup Data On/Off Schedule\n",
    "schedule.every().monday.at(\"14:30\").do(DataOn)\n",
    "schedule.every().monday.at(\"21:00\").do(DataOff)\n",
    "schedule.every().tuesday.at(\"14:30\").do(DataOn)\n",
    "schedule.every().tuesday.at(\"21:00\").do(DataOff)\n",
    "schedule.every().wednesday.at(\"14:30\").do(DataOn)\n",
    "schedule.every().wednesday.at(\"21:00\").do(DataOff)\n",
    "schedule.every().thursday.at(\"14:30\").do(DataOn)\n",
    "schedule.every().thursday.at(\"21:00\").do(DataOff)\n",
    "schedule.every().friday.at(\"14:30\").do(DataOn)\n",
    "schedule.every().friday.at(\"21:00\").do(DataOff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    \n",
    "    #Here need to read the publish and log to error table.\n",
    "    next_message = json.loads(event_queue.get_message().decode())\n",
    "    if next_message:\n",
    "        #log message to database\n",
    "        \n",
    "    \n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
