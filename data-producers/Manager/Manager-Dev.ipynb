{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code that needs to be inside the Twitter and the IEX notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# This will be in each data source code.\n",
    "#To setup the queue\n",
    "queue = REDIS.pubsub()\n",
    "#Subscribe to the queues one for the events and one for the log\n",
    "queue.subscribe('event_queue')\n",
    "queue.subscribe('log_queue')\n",
    "\n",
    "#Code to log to the event queue\n",
    "def send_event(source, kind, message):\n",
    "    event_time = datetime.datetime.now()\n",
    "    event = {\n",
    "            \"event_time\": event_time,\n",
    "            \"source\": source,\n",
    "            \"kind\" : kind,\n",
    "            \"message\" : message\n",
    "            }\n",
    "    payload = json.dumps(event)\n",
    "    REDIS.publish('event_queue', payload)\n",
    "\n",
    "def send_log(source, current_count, count_diff):\n",
    "    log_time = datetime.datetime.now()\n",
    "    log = {\n",
    "            \"log_time\": log_time,\n",
    "            \"source\": source,\n",
    "            \"current_count\" : current_count,\n",
    "            \"count_diff\" : count_diff\n",
    "            }\n",
    "    payload = json.dumps(log)\n",
    "    REDIS.publish('log_queue', payload)\n",
    "\n",
    "#This functions will replace writing the database in the source files. Need to then write to the datbase in the manager\n",
    "#How to handle the multiple channels? The get message has which channel. Just need to check it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Purpose:\n",
    "1. Setup the log table\n",
    "2. Setup the error table\n",
    "3. Setup the company list and set the Redis Value\n",
    "4. Control the Sync schedule (When to set the DataOn variable)\n",
    "5. Subscribe to the error subscription and log errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Imports ##################################\n",
    "import redis\n",
    "import json\n",
    "import schedule\n",
    "import time\n",
    "from datetime import date, datetime\n",
    "import os\n",
    "#from tzlocal import get_localzone\n",
    "\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect\n",
    "from sqlalchemy import MetaData\n",
    "from sqlalchemy import Table\n",
    "from sqlalchemy import Column\n",
    "from sqlalchemy import Integer, String, DateTime\n",
    "\n",
    "############# Redis Setup ##############################\n",
    "#Connect to the DataStore\n",
    "REDIS = redis.Redis(host='data_store')\n",
    "\n",
    "#To setup the queue\n",
    "queue = REDIS.pubsub()\n",
    "#Subscribe to the queues one for the events and one for the log\n",
    "queue.subscribe('event_queue')\n",
    "queue.subscribe('log_queue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Table Exists\n",
      "Event Table Exists\n"
     ]
    }
   ],
   "source": [
    "############# Setup Database ###########################\n",
    "# User = %env DB_USER\n",
    "# password = %env DB_PWD\n",
    "# dbname = %env DB_NAME\n",
    "\n",
    "User = os.environ['DB_USER']\n",
    "password = os.environ['DB_PWD']\n",
    "dbname = os.environ['DB_NAME']\n",
    "\n",
    "engine = create_engine('mysql+mysqlconnector://{}:{}@db:3306/{}'.format(User, password, dbname), echo=False)\n",
    "conn = engine.connect()\n",
    "\n",
    "\n",
    "\n",
    "#Check to see if the tables are created and if not, create them\n",
    "meta = MetaData(engine)\n",
    "\n",
    "#Create log table\n",
    "if not engine.dialect.has_table(engine, 'log'):\n",
    "    print('Log Table does not exist')\n",
    "    print('Log Table being created....')\n",
    "    #Time, Source, Current Count, Count Diff\n",
    "    t1 = Table('log', meta,\n",
    "                 Column('log_time', DateTime, default=datetime.datetime.utcnow),\n",
    "                 Column('Source', String(30)),\n",
    "                 Column('Current_Count', Integer),\n",
    "                 Column('Count_Diff', Integer))\n",
    "    t1.create()\n",
    "else:\n",
    "    print('Log Table Exists')\n",
    "\n",
    "#Create event table\n",
    "if not engine.dialect.has_table(engine, 'event'):\n",
    "    print('Event Table does not exist')\n",
    "    print('Event Table being created....')\n",
    "    #Time, Source, Current Count, Count Diff\n",
    "    t1 = Table('event', meta,\n",
    "                 Column('event_time', DateTime, default=datetime.datetime.utcnow),\n",
    "                 Column('Source', String(30)),\n",
    "                 Column('Kind', String(30)),\n",
    "                 Column('Message', String(8000)))\n",
    "    t1.create()\n",
    "else:\n",
    "    print('Event Table Exists')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:14: SADeprecationWarning: reflect=True is deprecate; please use the reflect() method.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "################## Define Functions ##############################\n",
    "\n",
    "#Serialize datetime.\n",
    "def json_serial(obj):\n",
    "    \"\"\"JSON serializer for objects not serializable by default json code\"\"\"\n",
    "\n",
    "    if isinstance(obj, (datetime, date)):\n",
    "        return obj.isoformat()\n",
    "    raise TypeError (\"Type %s not serializable\" % type(obj))\n",
    "\n",
    "\n",
    "\n",
    "#Create table object\n",
    "meta = MetaData(engine,reflect=True)\n",
    "log_table = meta.tables['log']\n",
    "\n",
    "def database_log(log_data):\n",
    "    #Need to log these items to a database.\n",
    "    #Convert the data\n",
    "    log_data = json.loads(log_data)\n",
    "    print('------ Database Log Data --------')\n",
    "    print(log_data)\n",
    "    ins = log_table.insert().values(\n",
    "            log_time = log_data['log_time'],\n",
    "            Source = log_data['source'],\n",
    "            Current_Count = log_data['current_count'],\n",
    "            Count_Diff = log_data['count_diff']\n",
    "               )\n",
    "    conn.execute(ins)\n",
    "    print('Logged Log Data')\n",
    "    \n",
    "#Create table object\n",
    "#meta = MetaData(engine,reflect=True)\n",
    "event_table = meta.tables['event']\n",
    "\n",
    "def database_event(event_data):\n",
    "    #Need to log these items to a database.\n",
    "    event_data = json.loads(event_data)\n",
    "    \n",
    "    ins = event_table.insert().values(\n",
    "            event_time = event_data['event_time'],\n",
    "            Source = event_data['source'],\n",
    "            Kind=event_data['kind'],\n",
    "            Message=event_data['message']\n",
    "               )\n",
    "    conn.execute(ins)\n",
    "    print('Logged Event Data')\n",
    "\n",
    "#Event Kind Types\n",
    "#Activity, Error\n",
    "    \n",
    "#Manager will send itself a message when it turns data on and off    \n",
    "def send_event(source, kind, message):\n",
    "    event_time = datetime.now()\n",
    "    event_time = json_serial(event_time)\n",
    "    event = {\n",
    "            \"event_time\": event_time,\n",
    "            \"source\": source,\n",
    "            \"kind\" : kind,\n",
    "            \"message\" : message\n",
    "            }\n",
    "    payload = json.dumps(event)\n",
    "    REDIS.publish('event_queue', payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### Set up the company list #####################\n",
    "companies = {\n",
    "    \"AAPL\":\"Apple\",\n",
    "    \"FB\":\"Facebook\",\n",
    "    \"GOOG\":\"Google Alphabet C\",\n",
    "    \"GOOGL\":\"Google Alphabet A\",\n",
    "    \"AMZN\":\"Amazon\",\n",
    "    \"MSFT\":\"Microsoft\",\n",
    "    \"BAC\":\"Bank of America\",\n",
    "    \"BA\":\"Boeing\",\n",
    "    \"NFLX\":\"Netflix\",\n",
    "    \"JPM\":\"JPMorgan Chase\",\n",
    "    \"TSLA\":\"Tesla\",\n",
    "    \"CSCO\":\"Cisco Systems\",\n",
    "    \"XOM\":\"Exxon Mobil\",\n",
    "    \"WFC\":\"Wells Fargo\",\n",
    "    \"V\":\"Visa\",\n",
    "    \"JNJ\":\"Johnson & Johnson\",\n",
    "    \"PFE\" :\"Pfizer\",\n",
    "    \"INTC\":\"Intel\",\n",
    "    \"HD\":\"Home Depot\",\n",
    "    \"C\":\"Citigroup\",\n",
    "    \"UTX\":\"United Technologies\",\n",
    "    \"CMCSA\":\"Comcast\",\n",
    "    \"TWTR\":\"Twitter\",\n",
    "    \"GE\":\"General Electric\",\n",
    "    \"UNH\":\"United Health Group\",\n",
    "    \"PCLN\":\"Priceline Group\",\n",
    "    \"BABA\":\"Alibaba Group\",\n",
    "    \"NVDA\":\"NVIDIA\"\n",
    "    \n",
    "    }\n",
    "REDIS.set('companies', json.dumps(companies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Setup the Data ON Flag #################\n",
    "REDIS.set('Data_On',0)\n",
    "\n",
    "#Create Explicit Data On/Off Functions\n",
    "def DataOn():\n",
    "    REDIS.set('Data_On',1)\n",
    "    send_event('Manager', 'Activity', 'Data flag On')\n",
    "    \n",
    "\n",
    "def DataOff():\n",
    "    REDIS.set('Data_On',0)\n",
    "    send_event('Manager', 'Activity', 'Data flag Off')\n",
    "    \n",
    "# global past_twitter_count\n",
    "# past_tweet_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn on if starts during open times\n",
    "now = datetime.now()\n",
    "\n",
    "if now.hour >= 14 and now.hour < 21:\n",
    "    if now.hour == 14 and now.minute >= 30:\n",
    "        DataOn()\n",
    "    elif now.hour > 14:\n",
    "        DataOn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Every 1 week at 21:00:00 do DataOff() (last run: [never], next run: 2018-02-23 21:00:00)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## Setup Schedules ######################\n",
    "#Since the market isnt open all day, want to control when turn data fetch on and off\n",
    "\n",
    "#Time in 24 hour clocks and UTC time\n",
    "schedule.clear()\n",
    "#Setup Data On/Off Schedule\n",
    "schedule.every().monday.at(\"14:30\").do(DataOn)\n",
    "schedule.every().monday.at(\"21:00\").do(DataOff)\n",
    "schedule.every().tuesday.at(\"14:30\").do(DataOn)\n",
    "schedule.every().tuesday.at(\"21:00\").do(DataOff)\n",
    "schedule.every().wednesday.at(\"14:30\").do(DataOn)\n",
    "schedule.every().wednesday.at(\"21:00\").do(DataOff)\n",
    "schedule.every().thursday.at(\"14:30\").do(DataOn)\n",
    "schedule.every().thursday.at(\"21:00\").do(DataOff)\n",
    "schedule.every().friday.at(\"14:30\").do(DataOn)\n",
    "schedule.every().friday.at(\"21:00\").do(DataOff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:30:46.116354\", \"source\": \"IEX\", \"current_count\": 256, \"count_diff\": 28}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:30:46.116354', 'source': 'IEX', 'current_count': 256, 'count_diff': 28}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:31:21.768270\", \"source\": \"IEX\", \"current_count\": 284, \"count_diff\": 28}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:31:21.768270', 'source': 'IEX', 'current_count': 284, 'count_diff': 28}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:31:57.399230\", \"source\": \"IEX\", \"current_count\": 312, \"count_diff\": 28}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:31:57.399230', 'source': 'IEX', 'current_count': 312, 'count_diff': 28}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:32:34.887762\", \"source\": \"IEX\", \"current_count\": 340, \"count_diff\": 28}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:32:34.887762', 'source': 'IEX', 'current_count': 340, 'count_diff': 28}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:33:16.829300\", \"source\": \"IEX\", \"current_count\": 368, \"count_diff\": 28}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:33:16.829300', 'source': 'IEX', 'current_count': 368, 'count_diff': 28}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:33:54.502085\", \"source\": \"IEX\", \"current_count\": 396, \"count_diff\": 28}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:33:54.502085', 'source': 'IEX', 'current_count': 396, 'count_diff': 28}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:34:29.890408\", \"source\": \"IEX\", \"current_count\": 424, \"count_diff\": 28}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:34:29.890408', 'source': 'IEX', 'current_count': 424, 'count_diff': 28}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:35:05.168444\", \"source\": \"IEX\", \"current_count\": 452, \"count_diff\": 28}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:35:05.168444', 'source': 'IEX', 'current_count': 452, 'count_diff': 28}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:35:41.325299\", \"source\": \"IEX\", \"current_count\": 480, \"count_diff\": 28}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:35:41.325299', 'source': 'IEX', 'current_count': 480, 'count_diff': 28}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:36:16.914858\", \"source\": \"IEX\", \"current_count\": 508, \"count_diff\": 28}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:36:16.914858', 'source': 'IEX', 'current_count': 508, 'count_diff': 28}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:36:52.266315\", \"source\": \"IEX\", \"current_count\": 536, \"count_diff\": 28}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:36:52.266315', 'source': 'IEX', 'current_count': 536, 'count_diff': 28}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:37:28.177327\", \"source\": \"IEX\", \"current_count\": 564, \"count_diff\": 28}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:37:28.177327', 'source': 'IEX', 'current_count': 564, 'count_diff': 28}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:38:05.975981\", \"source\": \"IEX\", \"current_count\": 592, \"count_diff\": 28}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:38:05.975981', 'source': 'IEX', 'current_count': 592, 'count_diff': 28}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:38:41.367940\", \"source\": \"IEX\", \"current_count\": 620, \"count_diff\": 28}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:38:41.367940', 'source': 'IEX', 'current_count': 620, 'count_diff': 28}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:39:16.745489\", \"source\": \"IEX\", \"current_count\": 648, \"count_diff\": 28}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:39:16.745489', 'source': 'IEX', 'current_count': 648, 'count_diff': 28}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:39:52.836327\", \"source\": \"IEX\", \"current_count\": 676, \"count_diff\": 28}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:39:52.836327', 'source': 'IEX', 'current_count': 676, 'count_diff': 28}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:40:32.685207\", \"source\": \"IEX\", \"current_count\": 704, \"count_diff\": 28}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:40:32.685207', 'source': 'IEX', 'current_count': 704, 'count_diff': 28}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:41:08.097064\", \"source\": \"IEX\", \"current_count\": 732, \"count_diff\": 28}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:41:08.097064', 'source': 'IEX', 'current_count': 732, 'count_diff': 28}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:41:43.488153\", \"source\": \"IEX\", \"current_count\": 760, \"count_diff\": 28}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:41:43.488153', 'source': 'IEX', 'current_count': 760, 'count_diff': 28}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:42:20.656782\", \"source\": \"IEX\", \"current_count\": 788, \"count_diff\": 28}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:42:20.656782', 'source': 'IEX', 'current_count': 788, 'count_diff': 28}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'event_queue', 'data': b'{\"event_time\": \"2018-02-19T19:43:18.147237\", \"source\": \"Twitter\", \"kind\": \"Activity\", \"message\": \"Data Source Started\"}'}\n",
      "Logged Event Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:43:48.210294\", \"source\": \"Twitter\", \"current_count\": 2, \"count_diff\": 2}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:43:48.210294', 'source': 'Twitter', 'current_count': 2, 'count_diff': 2}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:44:18.275171\", \"source\": \"Twitter\", \"current_count\": 5, \"count_diff\": 3}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:44:18.275171', 'source': 'Twitter', 'current_count': 5, 'count_diff': 3}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:44:48.328907\", \"source\": \"Twitter\", \"current_count\": 11, \"count_diff\": 6}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:44:48.328907', 'source': 'Twitter', 'current_count': 11, 'count_diff': 6}\n",
      "Logged Log Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:45:18.390199\", \"source\": \"Twitter\", \"current_count\": 14, \"count_diff\": 3}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:45:18.390199', 'source': 'Twitter', 'current_count': 14, 'count_diff': 3}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:45:48.452658\", \"source\": \"Twitter\", \"current_count\": 18, \"count_diff\": 4}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:45:48.452658', 'source': 'Twitter', 'current_count': 18, 'count_diff': 4}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'event_queue', 'data': b'{\"event_time\": \"2018-02-19T19:46:50.772224\", \"source\": \"IEX\", \"kind\": \"Activity\", \"message\": \"Data Source Started\"}'}\n",
      "Logged Event Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-02-19T19:47:32.799679\", \"source\": \"IEX\", \"current_count\": 28, \"count_diff\": 28}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-02-19T19:47:32.799679', 'source': 'IEX', 'current_count': 28, 'count_diff': 28}\n",
      "Logged Log Data\n"
     ]
    }
   ],
   "source": [
    "########### Execute ############################\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    \n",
    "    #May need to add in another while loop here. But we shall see after testing.\n",
    "    \n",
    "    next_message = queue.get_message()\n",
    "    #next_message = json.loads(queue.get_message()['data'].decode())\n",
    "    if next_message:\n",
    "        print('------ REDIS Message -------')\n",
    "        print(next_message)\n",
    "        #Ignore the initial 1 or 2 that comes out of the queue.\n",
    "        try:\n",
    "            payload = next_message['data'].decode()\n",
    "            #check which queue\n",
    "            if next_message['channel'].decode() == 'event_queue':\n",
    "                #Call database_event function to log to database\n",
    "                database_event(payload)\n",
    "                #Eventually can check the kind of event and do different action if error.\n",
    "        \n",
    "            if next_message['channel'].decode() == 'log_queue':\n",
    "                #Call database_log function to log to database\n",
    "                database_log(payload)\n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "    \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_test = {\"log_time\": \"2018-02-05T00:37:45.578451\", \"source\": \"IEX\", \"current_count\": 12, \"count_diff\": 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-02-05T00:37:45.578451'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_test['log_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
