{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Purpose:\n",
    "1. Setup the log table\n",
    "2. Setup the error table\n",
    "3. Setup the company list and set the Redis Value\n",
    "4. Control the Sync schedule (When to set the DataOn variable)\n",
    "5. Subscribe to the error subscription and log errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Imports ##################################\n",
    "import redis\n",
    "import json\n",
    "import schedule\n",
    "import time\n",
    "from datetime import date, datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect\n",
    "from sqlalchemy import MetaData\n",
    "from sqlalchemy import Table\n",
    "from sqlalchemy import Column\n",
    "from sqlalchemy import Integer, String, DateTime\n",
    "\n",
    "############# Redis Setup ##############################\n",
    "#Connect to the DataStore\n",
    "REDIS = redis.Redis(host='data_store')\n",
    "\n",
    "#To setup the queue\n",
    "queue = REDIS.pubsub()\n",
    "#Subscribe to the queues one for the events and one for the log\n",
    "queue.subscribe('event_queue')\n",
    "queue.subscribe('log_queue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Table Exists\n",
      "Event Table Exists\n"
     ]
    }
   ],
   "source": [
    "############# Setup Database ###########################\n",
    "# User = %env DB_USER\n",
    "# password = %env DB_PWD\n",
    "# dbname = %env DB_NAME\n",
    "\n",
    "User = os.environ['DB_USER']\n",
    "password = os.environ['DB_PWD']\n",
    "dbname = os.environ['DB_NAME']\n",
    "\n",
    "engine = create_engine('mysql+mysqlconnector://{}:{}@db:3306/{}'.format(User, password, dbname), echo=False)\n",
    "conn = engine.connect()\n",
    "\n",
    "\n",
    "\n",
    "#Check to see if the tables are created and if not, create them\n",
    "meta = MetaData(engine)\n",
    "\n",
    "#Create log table\n",
    "if not engine.dialect.has_table(engine, 'log'):\n",
    "    print('Log Table does not exist')\n",
    "    print('Log Table being created....')\n",
    "    #Time, Source, Current Count, Count Diff\n",
    "    t1 = Table('log', meta,\n",
    "                 Column('log_time', DateTime, default=datetime.utcnow),\n",
    "                 Column('Source', String(30)),\n",
    "                 Column('Current_Count', Integer),\n",
    "                 Column('Count_Diff', Integer))\n",
    "    t1.create()\n",
    "else:\n",
    "    print('Log Table Exists')\n",
    "\n",
    "#Create event table\n",
    "if not engine.dialect.has_table(engine, 'event'):\n",
    "    print('Event Table does not exist')\n",
    "    print('Event Table being created....')\n",
    "    #Time, Source, Current Count, Count Diff\n",
    "    t1 = Table('event', meta,\n",
    "                 Column('event_time', DateTime, default=datetime.utcnow),\n",
    "                 Column('Source', String(30)),\n",
    "                 Column('Kind', String(30)),\n",
    "                 Column('Message', String(8000)))\n",
    "    t1.create()\n",
    "else:\n",
    "    print('Event Table Exists')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:14: SADeprecationWarning: reflect=True is deprecate; please use the reflect() method.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "################## Define Functions ##############################\n",
    "\n",
    "#Serialize datetime.\n",
    "def json_serial(obj):\n",
    "    \"\"\"JSON serializer for objects not serializable by default json code\"\"\"\n",
    "\n",
    "    if isinstance(obj, (datetime, date)):\n",
    "        return obj.isoformat()\n",
    "    raise TypeError (\"Type %s not serializable\" % type(obj))\n",
    "\n",
    "\n",
    "\n",
    "#Create table object\n",
    "meta = MetaData(engine,reflect=True)\n",
    "log_table = meta.tables['log']\n",
    "\n",
    "def database_log(log_data):\n",
    "    #Need to log these items to a database.\n",
    "    #Convert the data\n",
    "    log_data = json.loads(log_data)\n",
    "    print('------ Database Log Data --------')\n",
    "    print(log_data)\n",
    "    ins = log_table.insert().values(\n",
    "            log_time = log_data['log_time'],\n",
    "            Source = log_data['source'],\n",
    "            Current_Count = log_data['current_count'],\n",
    "            Count_Diff = log_data['count_diff']\n",
    "               )\n",
    "    conn.execute(ins)\n",
    "    print('Logged Log Data')\n",
    "    \n",
    "#Create table object\n",
    "#meta = MetaData(engine,reflect=True)\n",
    "event_table = meta.tables['event']\n",
    "\n",
    "def database_event(event_data):\n",
    "    #Need to log these items to a database.\n",
    "    event_data = json.loads(event_data)\n",
    "    \n",
    "    ins = event_table.insert().values(\n",
    "            event_time = event_data['event_time'],\n",
    "            Source = event_data['source'],\n",
    "            Kind=event_data['kind'],\n",
    "            Message=event_data['message']\n",
    "               )\n",
    "    conn.execute(ins)\n",
    "    print('Logged Event Data')\n",
    "\n",
    "#Event Kind Types\n",
    "#Activity, Error\n",
    "    \n",
    "#Manager will send itself a message when it turns data on and off    \n",
    "def send_event(source, kind, message):\n",
    "    event_time = datetime.now()\n",
    "    event_time = json_serial(event_time)\n",
    "    event = {\n",
    "            \"event_time\": event_time,\n",
    "            \"source\": source,\n",
    "            \"kind\" : kind,\n",
    "            \"message\" : message\n",
    "            }\n",
    "    payload = json.dumps(event)\n",
    "    REDIS.publish('event_queue', payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Set up Feature Flag #####################\n",
    "\n",
    "#Setup file read and set state\n",
    "\n",
    "def update_flags_from_file():\n",
    "    feature_flags = pd.read_csv('feature_flag.csv', index_col='Feature')\n",
    "    #Set the feture flags in REDIS\n",
    "    REDIS.set('feature_flags', feature_flags.to_msgpack(compress='zlib'))\n",
    "    \n",
    "def get_feature_flag(feature):\n",
    "    all_flags = pd.read_msgpack(REDIS.get(\"feature_flags\"))\n",
    "    \n",
    "    try:\n",
    "        return all_flags.get_value(feature, 'State')\n",
    "        \n",
    "    except:\n",
    "        return 'Flag Not Found, not a valid feature flag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### Set up the company list #####################\n",
    "companies = {\n",
    "    \"AAPL\":\"Apple\",\n",
    "    \"FB\":\"Facebook\",\n",
    "    \"GOOG\":\"Google Alphabet C\",\n",
    "    \"GOOGL\":\"Google Alphabet A\",\n",
    "    \"AMZN\":\"Amazon\",\n",
    "    \"MSFT\":\"Microsoft\",\n",
    "    \"BAC\":\"Bank of America\",\n",
    "    \"BA\":\"Boeing\",\n",
    "    \"NFLX\":\"Netflix\",\n",
    "    \"JPM\":\"JPMorgan Chase\",\n",
    "    \"TSLA\":\"Tesla\",\n",
    "    \"CSCO\":\"Cisco Systems\",\n",
    "    \"XOM\":\"Exxon Mobil\",\n",
    "    \"WFC\":\"Wells Fargo\",\n",
    "    \"V\":\"Visa\",\n",
    "    \"JNJ\":\"Johnson & Johnson\",\n",
    "    \"PFE\" :\"Pfizer\",\n",
    "    \"INTC\":\"Intel\",\n",
    "    \"HD\":\"Home Depot\",\n",
    "    \"C\":\"Citigroup\",\n",
    "    \"UTX\":\"United Technologies\",\n",
    "    \"CMCSA\":\"Comcast\",\n",
    "    \"TWTR\":\"Twitter\",\n",
    "    \"GE\":\"General Electric\",\n",
    "    \"UNH\":\"United Health Group\",\n",
    "    \"PCLN\":\"Priceline Group\",\n",
    "    \"BABA\":\"Alibaba Group\",\n",
    "    \"NVDA\":\"NVIDIA\"\n",
    "    \n",
    "    }\n",
    "REDIS.set('companies', json.dumps(companies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Setup the Data ON Flag #################\n",
    "REDIS.set('Data_On',0)\n",
    "\n",
    "#Create Explicit Data On/Off Functions\n",
    "def DataOn():\n",
    "    REDIS.set('Data_On',1)\n",
    "    send_event('Manager', 'Activity', 'Data flag On')\n",
    "    \n",
    "\n",
    "def DataOff():\n",
    "    REDIS.set('Data_On',0)\n",
    "    send_event('Manager', 'Activity', 'Data flag Off')\n",
    "    \n",
    "# global past_twitter_count\n",
    "# past_tweet_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn on if starts during open times\n",
    "now = datetime.now()\n",
    "\n",
    "if now.hour >= 14 and now.hour < 21:\n",
    "    if now.hour == 14 and now.minute >= 30:\n",
    "        DataOn()\n",
    "    elif now.hour > 14:\n",
    "        DataOn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Every 10 seconds do update_flags_from_file() (last run: [never], next run: 2018-03-05 19:39:55)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## Setup Schedules ######################\n",
    "#Since the market isnt open all day, want to control when turn data fetch on and off\n",
    "\n",
    "#Time in 24 hour clocks and UTC time\n",
    "schedule.clear()\n",
    "#Setup Data On/Off Schedule\n",
    "schedule.every().monday.at(\"14:30\").do(DataOn)\n",
    "schedule.every().monday.at(\"21:00\").do(DataOff)\n",
    "schedule.every().tuesday.at(\"14:30\").do(DataOn)\n",
    "schedule.every().tuesday.at(\"21:00\").do(DataOff)\n",
    "schedule.every().wednesday.at(\"14:30\").do(DataOn)\n",
    "schedule.every().wednesday.at(\"21:00\").do(DataOff)\n",
    "schedule.every().thursday.at(\"14:30\").do(DataOn)\n",
    "schedule.every().thursday.at(\"21:00\").do(DataOff)\n",
    "schedule.every().friday.at(\"14:30\").do(DataOn)\n",
    "schedule.every().friday.at(\"21:00\").do(DataOff)\n",
    "\n",
    "#Read the Feature Flag\n",
    "schedule.every(10).seconds.do(update_flags_from_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ REDIS Message -------\n",
      "{'type': 'subscribe', 'pattern': None, 'channel': b'event_queue', 'data': 1}\n",
      "------ REDIS Message -------\n",
      "{'type': 'subscribe', 'pattern': None, 'channel': b'log_queue', 'data': 2}\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'event_queue', 'data': b'{\"event_time\": \"2018-03-05T19:39:43.675919\", \"source\": \"Manager\", \"kind\": \"Activity\", \"message\": \"Data flag On\"}'}\n",
      "Logged Event Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'event_queue', 'data': b'{\"event_time\": \"2018-03-05T19:40:22.086349\", \"source\": \"Twitter\", \"kind\": \"Activity\", \"message\": \"Data Source Started\"}'}\n",
      "Logged Event Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-03-05T19:40:52.151502\", \"source\": \"Twitter\", \"current_count\": 1, \"count_diff\": 1}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-03-05T19:40:52.151502', 'source': 'Twitter', 'current_count': 1, 'count_diff': 1}\n",
      "Logged Log Data\n",
      "------ REDIS Message -------\n",
      "{'type': 'message', 'pattern': None, 'channel': b'log_queue', 'data': b'{\"log_time\": \"2018-03-05T19:41:22.225099\", \"source\": \"Twitter\", \"current_count\": 2, \"count_diff\": 1}'}\n",
      "------ Database Log Data --------\n",
      "{'log_time': '2018-03-05T19:41:22.225099', 'source': 'Twitter', 'current_count': 2, 'count_diff': 1}\n",
      "Logged Log Data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2759781462e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########### Execute ############################\n",
    "\n",
    "#Read Feature Flags at beginning\n",
    "update_flags_from_file()\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    \n",
    "    #May need to add in another while loop here. But we shall see after testing.\n",
    "    \n",
    "    next_message = queue.get_message()\n",
    "    #next_message = json.loads(queue.get_message()['data'].decode())\n",
    "    if next_message:\n",
    "        print('------ REDIS Message -------')\n",
    "        print(next_message)\n",
    "        #Ignore the initial 1 or 2 that comes out of the queue.\n",
    "        try:\n",
    "            payload = next_message['data'].decode()\n",
    "            #check which queue\n",
    "            if next_message['channel'].decode() == 'event_queue':\n",
    "                #Call database_event function to log to database\n",
    "                database_event(payload)\n",
    "                #Eventually can check the kind of event and do different action if error.\n",
    "        \n",
    "            if next_message['channel'].decode() == 'log_queue':\n",
    "                #Call database_log function to log to database\n",
    "                database_log(payload)\n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "    \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_test = {\"log_time\": \"2018-02-05T00:37:45.578451\", \"source\": \"IEX\", \"current_count\": 12, \"count_diff\": 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-02-05T00:37:45.578451'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_test['log_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
