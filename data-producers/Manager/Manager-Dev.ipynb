{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDIS = redis.Redis(host='data_store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "REDIS.set('my_incrementer', 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDIS.get('IEX_Stock_Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDIS.get('Twitter_Stock_Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Manager needs to do many things. One of which is manage the the company list and populate the data-store\n",
    "companies = {\n",
    "    \"AAPL\":\"Apple\",\n",
    "    \"FB\":\"Facebook\",\n",
    "    \"GOOG\":\"Google\"\n",
    "    }\n",
    "REDIS.set('companies', json.dumps(companies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TEst\n",
    "REDIS.set('test',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(REDIS.get('test')) ==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When setting up the flag, need to setup scheudle for the time, but also need to check if after open time\n",
    "# and before close time, and set the flag to true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tzlocal\n",
      "  Downloading tzlocal-1.5.1.tar.gz\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.6/site-packages (from tzlocal)\n",
      "Building wheels for collected packages: tzlocal\n",
      "  Running setup.py bdist_wheel for tzlocal ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ds/.cache/pip/wheels/7c/a1/5d/0f37ce6eb6eea391bd185f5747429a93519be115d007263bcf\n",
      "Successfully built tzlocal\n",
      "Installing collected packages: tzlocal\n",
      "Successfully installed tzlocal-1.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tzlocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the publish subscribe\n",
    "p = REDIS.pubsub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.subscribe('test-channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the same json dumps as setting the companies.\n",
    "payload = json.dumps({'event':'test'})\n",
    "REDIS.publish('test-channel', payload)\n",
    "#REDIS.publish('test-channel', 'other data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channel': b'test-channel', 'data': 1, 'pattern': None, 'type': 'subscribe'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Once publish teh data, can only read the data once. Once its read its gone.\n",
    "#Have to continuously pull off the queue.\n",
    "p.get_message()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data There\n"
     ]
    }
   ],
   "source": [
    "if p.get_message():\n",
    "    print('Data There')\n",
    "else:\n",
    "    print('Data Gone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-channel\n",
      "{'event': 'test'}\n"
     ]
    }
   ],
   "source": [
    "#To retreive data.\n",
    "message = p.get_message()\n",
    "print(message['channel'].decode())\n",
    "print(json.loads(message['data'].decode()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code that needs to be inside the Twitter and the IEX notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# This will be in each data source code.\n",
    "#To setup the queue\n",
    "queue = REDIS.pubsub()\n",
    "#Subscribe to the queues one for the events and one for the log\n",
    "queue.subscribe('event_queue')\n",
    "queue.subscribe('log_queue')\n",
    "\n",
    "#Code to log to the event queue\n",
    "def send_event(source, kind, message):\n",
    "    event_time = datetime.datetime.now()\n",
    "    event = {\n",
    "            \"event_time\": event_time,\n",
    "            \"source\": source,\n",
    "            \"kind\" : kind,\n",
    "            \"message\" : message\n",
    "            }\n",
    "    payload = json.dumps(event)\n",
    "    REDIS.publish('event_queue', payload)\n",
    "\n",
    "def send_log(source, current_count, count_diff):\n",
    "    log_time = datetime.datetime.now()\n",
    "    log = {\n",
    "            \"log_time\": log_time,\n",
    "            \"source\": source,\n",
    "            \"current_count\" : current_count,\n",
    "            \"count_diff\" : count_diff\n",
    "            }\n",
    "    payload = json.dumps(log)\n",
    "    REDIS.publish('log_queue', payload)\n",
    "\n",
    "#This functions will replace writing the database in the source files. Need to then write to the datbase in the manager\n",
    "#How to handle the multiple channels? The get message has which channel. Just need to check it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Purpose:\n",
    "1. Setup the log table\n",
    "2. Setup the error table\n",
    "3. Setup the company list and set the Redis Value\n",
    "4. Control the Sync schedule (When to set the DataOn variable)\n",
    "5. Subscribe to the error subscription and log errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Imports ##################################\n",
    "import redis\n",
    "import json\n",
    "import schedule\n",
    "import time\n",
    "import datetime\n",
    "#from tzlocal import get_localzone\n",
    "\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect\n",
    "from sqlalchemy import MetaData\n",
    "from sqlalchemy import Table\n",
    "from sqlalchemy import Column\n",
    "from sqlalchemy import Integer, String, DateTime\n",
    "\n",
    "############# Redis Setup ##############################\n",
    "#Connect to the DataStore\n",
    "REDIS = redis.Redis(host='data_store')\n",
    "\n",
    "#To setup the queue\n",
    "queue = REDIS.pubsub()\n",
    "#Subscribe to the queues one for the events and one for the log\n",
    "queue.subscribe('event_queue')\n",
    "queue.subscribe('log_queue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Table Exists\n",
      "Event Table does not exist\n",
      "Event Table being created....\n"
     ]
    }
   ],
   "source": [
    "############# Setup Database ###########################\n",
    "User = %env DB_USER\n",
    "password = %env DB_PWD\n",
    "dbname = %env DB_NAME\n",
    "\n",
    "\n",
    "engine = create_engine('mysql+mysqlconnector://{}:{}@db:3306/{}'.format(User, password, dbname), echo=False)\n",
    "inspector = inspect(engine)\n",
    "\n",
    "\n",
    "\n",
    "#Check to see if the tables are created and if not, create them\n",
    "meta = MetaData(engine)\n",
    "\n",
    "#Create log table\n",
    "if not engine.dialect.has_table(engine, 'log'):\n",
    "    print('Log Table does not exist')\n",
    "    print('Log Table being created....')\n",
    "    #Time, Source, Current Count, Count Diff\n",
    "    t1 = Table('log', meta,\n",
    "                 Column('log_time', DateTime, default=datetime.datetime.utcnow),\n",
    "                 Column('Source', String(30)),\n",
    "                 Column('Current_Count', Integer),\n",
    "                 Column('Count_Diff', Integer))\n",
    "    t1.create()\n",
    "else:\n",
    "    print('Log Table Exists')\n",
    "\n",
    "#Create event table\n",
    "if not engine.dialect.has_table(engine, 'event'):\n",
    "    print('Event Table does not exist')\n",
    "    print('Event Table being created....')\n",
    "    #Time, Source, Current Count, Count Diff\n",
    "    t1 = Table('event', meta,\n",
    "                 Column('event_time', DateTime, default=datetime.datetime.utcnow),\n",
    "                 Column('Source', String(30)),\n",
    "                 Column('Kind', String(30)),\n",
    "                 Column('Message', String(8000)))\n",
    "    t1.create()\n",
    "else:\n",
    "    print('Event Table Exists')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SADeprecationWarning: reflect=True is deprecate; please use the reflect() method.\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:21: SADeprecationWarning: reflect=True is deprecate; please use the reflect() method.\n"
     ]
    }
   ],
   "source": [
    "################## Define Functions ##############################\n",
    "\n",
    "#Database Function creation\n",
    "\n",
    "#Create table object\n",
    "meta = MetaData(engine,reflect=True)\n",
    "table = meta.tables['log']\n",
    "\n",
    "def database_log(log_data):\n",
    "    #Need to log these items to a database.\n",
    "    ins = table.insert().values(\n",
    "            log_time = log_data['log_time'],\n",
    "            Source = log_data['source'],\n",
    "            Current_Count=log_data['current_count'],\n",
    "            Count_Diff=log_data['count_diff']\n",
    "               )\n",
    "    conn.execute(ins)\n",
    "    print('Logged Log Data')\n",
    "    \n",
    "#Create table object\n",
    "meta = MetaData(engine,reflect=True)\n",
    "table = meta.tables['event']\n",
    "\n",
    "def database_event(event_data):\n",
    "    #Need to log these items to a database.\n",
    "    ins = table.insert().values(\n",
    "            event_time = event_data['event_time'],\n",
    "            Source = event_data['source'],\n",
    "            Kind=event_data['kind'],\n",
    "            Message=event_data['message']\n",
    "               )\n",
    "    conn.execute(ins)\n",
    "    print('Logged Event Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x7fd3ada03668>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test insert <DO NOT USE - This is just for testing purposes>\n",
    "conn = engine.connect()\n",
    "ins = t1.insert().values(\n",
    "            log_time = datetime.datetime.now(),\n",
    "            Source = 'Test',\n",
    "            Current_Count=42,\n",
    "            Count_Diff=5\n",
    "               )\n",
    "conn.execute(ins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### Set up the company list #####################\n",
    "companies = {\n",
    "    \"AAPL\":\"Apple\",\n",
    "    \"FB\":\"Facebook\",\n",
    "    \"GOOG\":\"Google\"\n",
    "    }\n",
    "REDIS.set('companies', json.dumps(companies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Setup the Data ON Flag #################\n",
    "REDIS.set('Data_On',0)\n",
    "\n",
    "#Create Explicit Data On/Off Functions\n",
    "def DataOn():\n",
    "    REDIS.set('Data_On',1)\n",
    "    \n",
    "\n",
    "def DataOff():\n",
    "    REDIS.set('Data_On',0)\n",
    "    \n",
    "global past_twitter_count\n",
    "past_tweet_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Turn on if starts during open times\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "if now.hour >= 14 and now.hour < 21:\n",
    "    if now.hour = 14 and now.minute >= 30:\n",
    "        DataOn()\n",
    "    elif now.hour > 14:\n",
    "        DataOn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Every 1 week at 21:00:00 do DataOff() (last run: [never], next run: 2018-02-09 21:00:00)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## Setup Schedules ######################\n",
    "#Since the market isnt open all day, want to control when turn data fetch on and off\n",
    "\n",
    "#Time in 24 hour clocks and UTC time\n",
    "schedule.clear()\n",
    "#Setup Data On/Off Schedule\n",
    "schedule.every().monday.at(\"14:30\").do(DataOn)\n",
    "schedule.every().monday.at(\"21:00\").do(DataOff)\n",
    "schedule.every().tuesday.at(\"14:30\").do(DataOn)\n",
    "schedule.every().tuesday.at(\"21:00\").do(DataOff)\n",
    "schedule.every().wednesday.at(\"14:30\").do(DataOn)\n",
    "schedule.every().wednesday.at(\"21:00\").do(DataOff)\n",
    "schedule.every().thursday.at(\"14:30\").do(DataOn)\n",
    "schedule.every().thursday.at(\"21:00\").do(DataOff)\n",
    "schedule.every().friday.at(\"14:30\").do(DataOn)\n",
    "schedule.every().friday.at(\"21:00\").do(DataOff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3e23f4eba5ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnext_message\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'channel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'event_queue'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m#Call database_event function to log to database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mdatabase_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnext_message\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'channel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'log_queue'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-f697e003864b>\u001b[0m in \u001b[0;36mdatabase_event\u001b[0;34m(event_data)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m#Need to log these items to a database.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     ins = table.insert().values(\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mevent_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'event_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mSource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mKind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevent_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kind'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "########### Execute ############################\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    \n",
    "    #May need to add in another while loop here. But we shall see after testing.\n",
    "    \n",
    "    next_message = queue.get_message()\n",
    "    #next_message = json.loads(queue.get_message()['data'].decode())\n",
    "    if next_message:\n",
    "        payload = next_message['data'].decode()\n",
    "        #check which queue\n",
    "        if next_message['channel'].decode() == 'event_queue':\n",
    "            #Call database_event function to log to database\n",
    "            database_event(payload)\n",
    "        \n",
    "        if next_message['channel'].decode() == 'log_queue':\n",
    "            #Call database_log function to log to database\n",
    "            database_log(payload)\n",
    "    \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
