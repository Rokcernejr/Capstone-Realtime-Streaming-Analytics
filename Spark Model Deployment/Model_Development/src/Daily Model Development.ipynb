{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Initialize ##################################\n",
    "\n",
    "# Basics\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import boto3\n",
    "import io\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import findspark\n",
    "# findspark.init('/usr/lib/spark')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('nlp').getOrCreate()\n",
    "import time\n",
    "\n",
    "# Feature Engineering\n",
    "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,\n",
    "                                Tokenizer,StopWordsRemover, CountVectorizer,IDF,StringIndexer, HashingTF)\n",
    "from pyspark.sql.functions import length\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import StringType\n",
    "import preprocessor as p\n",
    "from pyspark.sql.functions import dayofyear, concat_ws, collect_list, countDistinct\n",
    "\n",
    "# Models\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Evaluators\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Data ############################################\n",
    "\n",
    "#Setup Mongo and create the database and collection\n",
    "User = os.environ['MONGODB_USER']\n",
    "password = os.environ['MONGODB_PASS']\n",
    "IP = os.environ['IP']\n",
    "\n",
    "client = MongoClient(IP, username=User, password=password)\n",
    "db = client['stock_tweets']\n",
    "\n",
    "#Grab references\n",
    "twitter_coll_reference = db.twitter\n",
    "iex_coll_reference = db.iex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Build Twitter Pandas Frame #######################\n",
    "# Create Data Frame\n",
    "twitter_data = pd.DataFrame(list(twitter_coll_reference.find()))\n",
    "\n",
    "# Need to convert the created_at to a time stamp and set to index\n",
    "twitter_data.index=pd.to_datetime(twitter_data['created_at'])\n",
    "\n",
    "# Delimited the Company List into separate rows\n",
    "delimited_twitter_data=[]\n",
    "\n",
    "for item in twitter_data.itertuples():\n",
    "    #twitter_dict={}\n",
    "    for company in item[1]:\n",
    "        twitter_dict={}\n",
    "        twitter_dict['created_at']=item[0]\n",
    "        twitter_dict['company']=company\n",
    "        twitter_dict['text']=item[11]\n",
    "        twitter_dict['user_followers_count']=item[12]\n",
    "        twitter_dict['user_name']=item[13]\n",
    "        twitter_dict['user_statuses_count']=item[15]\n",
    "        delimited_twitter_data.append(twitter_dict)\n",
    "\n",
    "delimited_twitter_df = pd.DataFrame(delimited_twitter_data) \n",
    "#delimited_twitter_df.set_index('created_at', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Spark Dataframe\n",
    "# Create a Spark DataFrame from Pandas\n",
    "twitter_df = spark.createDataFrame(delimited_twitter_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+--------------------+--------------------+--------------------+-------------------+\n",
      "|company|         created_at|                text|user_followers_count|           user_name|user_statuses_count|\n",
      "+-------+-------------------+--------------------+--------------------+--------------------+-------------------+\n",
      "|   TSLA|2018-03-12 18:07:08|$TSLA so nice so ...|                1703|TradeTherapAnalytics|              67528|\n",
      "|   AAPL|2018-03-12 18:07:19|@JoKiddo But how ...|                2901|        Gilmo Report|              18524|\n",
      "|   AAPL|2018-03-12 18:07:23|RT @StockTwits: T...|                5256|           Mark Hill|              13523|\n",
      "|   GOOG|2018-03-12 18:07:23|RT @StockTwits: T...|                5256|           Mark Hill|              13523|\n",
      "|  GOOGL|2018-03-12 18:07:23|RT @StockTwits: T...|                5256|           Mark Hill|              13523|\n",
      "|   AAPL|2018-03-12 18:07:25|$AAPL may be work...|                 486|       William White|               7850|\n",
      "|   TWTR|2018-03-12 18:07:29|In 300 shares of ...|                 979|                Ross|              40293|\n",
      "|   NFLX|2018-03-12 18:07:33|$NFLX $318 BUY li...|                 890|             STOCKER|               6127|\n",
      "|   AMZN|2018-03-12 18:07:41|Amazon hits $1600...|                 254|            Renegade|               9233|\n",
      "|   TSLA|2018-03-12 18:07:43|$TSLA bears just ...|                 211|            Just Tex|                154|\n",
      "|   AMZN|2018-03-12 18:07:42|Americans reporte...|               14518|          Aaron Task|              21894|\n",
      "|   TSLA|2018-03-12 18:07:59|@nobullshytrader ...|                 997|            BossHogg|              32754|\n",
      "|   TSLA|2018-03-12 18:08:10|Vin 111xx just as...|                 451|        Eric Steiman|                304|\n",
      "|   AAPL|2018-03-12 18:08:23|RT @StockTwits: T...|                 306|     Gonzalo Escobar|               7043|\n",
      "|   GOOG|2018-03-12 18:08:23|RT @StockTwits: T...|                 306|     Gonzalo Escobar|               7043|\n",
      "|  GOOGL|2018-03-12 18:08:23|RT @StockTwits: T...|                 306|     Gonzalo Escobar|               7043|\n",
      "|      V|2018-03-12 18:08:24|Check which story...|                1145|             FinBuzz|             222708|\n",
      "|   AAPL|2018-03-12 18:08:26|chart via @OphirG...|               25683|       See It Market|              29036|\n",
      "|   AAPL|2018-03-12 18:08:26|RT @stockstreamtv...|                1962|      EquitiesTrader|              46602|\n",
      "|     FB|2018-03-12 18:08:26|RT @stockstreamtv...|                1962|      EquitiesTrader|              46602|\n",
      "+-------+-------------------+--------------------+--------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twitter_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to Group by Day and company\n",
    "twitter_daily_df = twitter_df.groupby(dayofyear(\"created_at\"),\"Company\").count().orderBy('dayofyear(created_at)','Company')\n",
    "twitter_daily_df = twitter_daily_df.select(col(\"dayofyear(created_at)\").alias(\"Day\"), \n",
    "                                           col(\"Company\").alias (\"Company\"), \n",
    "                                           col(\"count\").alias(\"Number_of_tweets\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the Text\n",
    "combined_text = twitter_df.groupby(dayofyear(\"created_at\"),\"Company\").agg(concat_ws(\" \", collect_list(\"text\"))).orderBy('dayofyear(created_at)','Company')\n",
    "combined_text = combined_text.select(col(\"dayofyear(created_at)\").alias(\"Day\"), \n",
    "                                           col(\"Company\").alias (\"Company\"), \n",
    "                                           col(\"concat_ws( , collect_list(text))\").alias(\"Text\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Text Data\n",
    "twitter_daily_df = twitter_daily_df.join(combined_text, [\"Day\",\"Company\"]).orderBy('Day','Company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distinct Users\n",
    "distinct_users = twitter_df.groupby(dayofyear(\"created_at\"),\"Company\").agg(countDistinct(\"user_name\")).orderBy('dayofyear(created_at)','Company')\n",
    "distinct_users = distinct_users.select(col(\"dayofyear(created_at)\").alias(\"Day\"), \n",
    "                                           col(\"Company\").alias (\"Company\"), \n",
    "                                           col(\"count(DISTINCT user_name)\").alias(\"Distinct_Users\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Distinct Users\n",
    "twitter_daily_df = twitter_daily_df.join(distinct_users, [\"Day\",\"Company\"]).orderBy('Day','Company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------------+--------------------+--------------+\n",
      "|Day|Company|Number_of_tweets|                Text|Distinct_Users|\n",
      "+---+-------+----------------+--------------------+--------------+\n",
      "| 71|   AAPL|             403|@JoKiddo But how ...|           258|\n",
      "| 71|   AMZN|             275|Amazon hits $1600...|           162|\n",
      "| 71|     BA|             137|Thus, its cheaper...|            94|\n",
      "| 71|   BABA|              50|Thus, its cheaper...|            37|\n",
      "| 71|    BAC|              51|Open an account w...|            35|\n",
      "| 71|      C|              73|We take a look at...|            59|\n",
      "| 71|  CMCSA|               8|3/12 Unusual Opti...|             6|\n",
      "| 71|   CSCO|               6|RT @CabotAnalysts...|             6|\n",
      "| 71|     FB|             128|RT @stockstreamtv...|            74|\n",
      "| 71|     GE|              51|.\n",
      "The signals Mar...|            43|\n",
      "| 71|   GOOG|             148|RT @StockTwits: T...|           104|\n",
      "| 71|  GOOGL|              81|RT @StockTwits: T...|            63|\n",
      "| 71|     HD|              15|3 Stocks to Buy W...|            12|\n",
      "| 71|   INTC|              41|We take a look at...|            28|\n",
      "| 71|    JNJ|              44|RT @JNTNews: .@Va...|            11|\n",
      "| 71|    JPM|              32|Colony Group LLC ...|            23|\n",
      "| 71|   MSFT|              95|RT @stockstreamtv...|            68|\n",
      "| 71|   NFLX|             220|$NFLX $318 BUY li...|           123|\n",
      "| 71|   NVDA|              53|RT @nobullshytrad...|            39|\n",
      "| 71|   PCLN|               5|$BKNG formerly $P...|             5|\n",
      "+---+-------+----------------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twitter_daily_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Build Stock Data ###########################\n",
    "stock_data = pd.DataFrame(list(iex_coll_reference.find()))\n",
    "\n",
    "# Need to convert the created_at to a time stamp\n",
    "stock_data.index=pd.to_datetime(stock_data['latestUpdate'])\n",
    "stock_data['latestUpdate'] = pd.to_datetime(stock_data['latestUpdate'])\n",
    "#Group By hourly and stock price\n",
    "# Need to get the first stock price in teh hour, and then the last to take the difference to see how much change.\n",
    "stock_delimited_daily = stock_data.sort_values('latestUpdate').groupby([pd.Grouper(freq=\"D\"), 'Ticker']).first()['latestPrice'].to_frame()\n",
    "stock_delimited_daily.columns = ['First_Price']\n",
    "stock_delimited_daily['Last_Price'] = stock_data.sort_values('latestUpdate').groupby([pd.Grouper(freq=\"D\"), 'Ticker']).last()['latestPrice']\n",
    "\n",
    "# Then need to take the difference and turn into a percentage.\n",
    "stock_delimited_daily['Price_Percent_Change'] = ((stock_delimited_daily['Last_Price'] \n",
    "                                                   - stock_delimited_daily['First_Price'])/stock_delimited_daily['First_Price'])*100\n",
    "\n",
    "# Need to also show Percent from open price\n",
    "stock_delimited_daily['Open_Price'] = stock_data.groupby([pd.Grouper(freq=\"D\"), 'Ticker'])['open'].mean()\n",
    "stock_delimited_daily['Price_Percent_Open'] = ((stock_delimited_daily['Last_Price'] \n",
    "                                                 - stock_delimited_daily['Open_Price'])/stock_delimited_daily['Open_Price'])*100\n",
    "\n",
    "# Also include mean volume\n",
    "stock_delimited_daily['Mean_Volume'] = stock_data.groupby([pd.Grouper(freq=\"D\"), 'Ticker'])['latestVolume'].mean()\n",
    "\n",
    "# Classification Labels\n",
    "stock_delimited_daily['Price_Change'] = np.where(stock_delimited_daily['Price_Percent_Change']>=0, 1, 0)\n",
    "stock_delimited_daily['Open_Price_Change'] = np.where(stock_delimited_daily['Price_Percent_Open']>=0, 1, 0)\n",
    "\n",
    "# Rename the Index\n",
    "stock_delimited_daily = stock_delimited_daily.reindex(stock_delimited_daily.index.rename(['Time', 'Company']))\n",
    "\n",
    "# Flatten Dataframe\n",
    "stock_delimited_daily.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark DataFrame from Pandas\n",
    "stock_df = spark.createDataFrame(stock_delimited_daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+-----------+----------+--------------------+------------------+--------------------+--------------------+------------+-----------------+\n",
      "|               Time|Company|First_Price|Last_Price|Price_Percent_Change|        Open_Price|  Price_Percent_Open|         Mean_Volume|Price_Change|Open_Price_Change|\n",
      "+-------------------+-------+-----------+----------+--------------------+------------------+--------------------+--------------------+------------+-----------------+\n",
      "|2018-02-26 00:00:00|   PCLN|    1905.64|   1905.64|                 0.0|1905.9499999994837|-0.01626485476972973|            566730.0|           1|                0|\n",
      "|2018-03-12 00:00:00|   AAPL|     181.73|    181.75|0.011005337588736166|180.22999999999962|  0.8433668090775026|2.7673734089171976E7|           1|                1|\n",
      "|2018-03-12 00:00:00|   AMZN|   1600.745|   1598.39| -0.1471189977166751| 1592.600000000004|  0.3635564485744119|   4376276.694267516|           0|                1|\n",
      "|2018-03-12 00:00:00|     BA|     345.91|    344.19| -0.4972391662571267| 355.0199999999989|  -3.050532364373539|   5150044.363057325|           0|                0|\n",
      "|2018-03-12 00:00:00|   BABA|      192.9|    192.74|-0.08294453084499565|             192.0|  0.3854166666666714|1.6222451343949044E7|           0|                1|\n",
      "|2018-03-12 00:00:00|    BAC|      32.98|     32.84|-0.42449969678591104| 32.67000000000006|  0.5203550658094416| 4.670738411464968E7|           0|                1|\n",
      "|2018-03-12 00:00:00|      C|      76.39|     76.02| -0.4843565911768616| 76.09000000000012| -0.0919963201473531|    9991234.74522293|           0|                0|\n",
      "|2018-03-12 00:00:00|  CMCSA|      36.95|     36.96|0.027063599458722623| 37.09000000000008|-0.35049878673518586|1.3524678229299363E7|           1|                0|\n",
      "|2018-03-12 00:00:00|   CSCO|     45.675|     45.55|-0.27367268746579093| 45.55000000000012|-2.65186092380278...|1.4644756936305733E7|           0|                0|\n",
      "|2018-03-12 00:00:00|     FB|     185.46|    184.76| -0.3774398792192478| 185.2599999999994| -0.2698909640502023|1.2538169917197453E7|           0|                0|\n",
      "|2018-03-12 00:00:00|     GE|     15.075|      15.1| 0.16583747927031744|15.019999999999985|  0.5326231691079518| 5.952179287898089E7|           1|                1|\n",
      "|2018-03-12 00:00:00|   GOOG|   1172.005|    1164.5| -0.6403556298821343|1163.8500000000033| 0.05584912145007333|  1746562.7770700636|           0|                1|\n",
      "|2018-03-12 00:00:00|  GOOGL|    1173.88|   1165.93|  -0.677241285310257|            1165.0| 0.07982832618026298|  1900389.2229299364|           0|                1|\n",
      "|2018-03-12 00:00:00|     HD|     180.11|    179.71|  -0.222086502692802|182.43000000000023| -1.4909828427343215|  3773587.6624203823|           0|                0|\n",
      "|2018-03-12 00:00:00|   INTC|      51.36|     51.52|   0.311526479750786| 51.85999999999986|  -0.655611261087264| 2.581666484713376E7|           1|                0|\n",
      "|2018-03-12 00:00:00|    JNJ|     132.93|    132.63|-0.22568269013767497| 133.7999999999996|  -0.874439461883125|  3698224.5987261147|           0|                0|\n",
      "|2018-03-12 00:00:00|    JPM|     117.93|    117.66|-0.22894937674892754|             118.0| -0.2881355932203419|   9534050.853503184|           0|                0|\n",
      "|2018-03-12 00:00:00|   MSFT|      97.05|     96.77|-0.28851107676455556| 96.53000000000026|  0.2486273697293468|2.1210806630573247E7|           0|                1|\n",
      "|2018-03-12 00:00:00|   NFLX|     319.25|     321.3|    0.64212999216915| 333.5599999999995|  -3.675500659551355|1.7660935617834397E7|           1|                0|\n",
      "|2018-03-12 00:00:00|   NVDA|     250.76|    249.76|-0.39878768543627374|             247.0|  1.1174089068825874|1.3691184248407643E7|           0|                1|\n",
      "+-------------------+-------+-----------+----------+--------------------+------------------+--------------------+--------------------+------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stock_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df = stock_df.withColumn(\"Day\", dayofyear(\"Time\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+\n",
      "|               Time|Day|\n",
      "+-------------------+---+\n",
      "|2018-02-26 00:00:00| 57|\n",
      "|2018-03-12 00:00:00| 71|\n",
      "|2018-03-12 00:00:00| 71|\n",
      "|2018-03-12 00:00:00| 71|\n",
      "|2018-03-12 00:00:00| 71|\n",
      "|2018-03-12 00:00:00| 71|\n",
      "|2018-03-12 00:00:00| 71|\n",
      "|2018-03-12 00:00:00| 71|\n",
      "|2018-03-12 00:00:00| 71|\n",
      "|2018-03-12 00:00:00| 71|\n",
      "|2018-03-12 00:00:00| 71|\n",
      "|2018-03-12 00:00:00| 71|\n",
      "|2018-03-12 00:00:00| 71|\n",
      "|2018-03-12 00:00:00| 71|\n",
      "|2018-03-12 00:00:00| 71|\n",
      "|2018-03-12 00:00:00| 71|\n",
      "|2018-03-12 00:00:00| 71|\n",
      "|2018-03-12 00:00:00| 71|\n",
      "|2018-03-12 00:00:00| 71|\n",
      "|2018-03-12 00:00:00| 71|\n",
      "+-------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stock_df.select([\"Time\", \"Day\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine The Data\n",
    "daily_df = twitter_daily_df.join(stock_df, [\"Day\",\"Company\"]).orderBy('Day','Company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------------+--------------------+--------------+-------------------+-----------+----------+--------------------+------------------+------------------+--------------------+------------+-----------------+\n",
      "|Day|Company|Number_of_tweets|                Text|Distinct_Users|               Time|First_Price|Last_Price|Price_Percent_Change|        Open_Price|Price_Percent_Open|         Mean_Volume|Price_Change|Open_Price_Change|\n",
      "+---+-------+----------------+--------------------+--------------+-------------------+-----------+----------+--------------------+------------------+------------------+--------------------+------------+-----------------+\n",
      "| 71|   AAPL|             403|@JoKiddo But how ...|           258|2018-03-12 00:00:00|     181.73|    181.75|0.011005337588736166|180.22999999999962|0.8433668090775026|2.7673734089171976E7|           1|                1|\n",
      "| 71|   AMZN|             275|Amazon hits $1600...|           162|2018-03-12 00:00:00|   1600.745|   1598.39| -0.1471189977166751| 1592.600000000004|0.3635564485744119|   4376276.694267516|           0|                1|\n",
      "| 71|     BA|             137|Thus, its cheaper...|            94|2018-03-12 00:00:00|     345.91|    344.19| -0.4972391662571267| 355.0199999999989|-3.050532364373539|   5150044.363057325|           0|                0|\n",
      "| 71|   BABA|              50|Thus, its cheaper...|            37|2018-03-12 00:00:00|      192.9|    192.74|-0.08294453084499565|             192.0|0.3854166666666714|1.6222451343949044E7|           0|                1|\n",
      "| 71|    BAC|              51|Open an account w...|            35|2018-03-12 00:00:00|      32.98|     32.84|-0.42449969678591104| 32.67000000000006|0.5203550658094416| 4.670738411464968E7|           0|                1|\n",
      "+---+-------+----------------+--------------------+--------------+-------------------+-----------+----------+--------------------+------------------+------------------+--------------------+------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "daily_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Day: integer (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Number_of_tweets: long (nullable = false)\n",
      " |-- Text: string (nullable = false)\n",
      " |-- Distinct_Users: long (nullable = false)\n",
      " |-- Time: timestamp (nullable = true)\n",
      " |-- First_Price: double (nullable = true)\n",
      " |-- Last_Price: double (nullable = true)\n",
      " |-- Price_Percent_Change: double (nullable = true)\n",
      " |-- Open_Price: double (nullable = true)\n",
      " |-- Price_Percent_Open: double (nullable = true)\n",
      " |-- Mean_Volume: double (nullable = true)\n",
      " |-- Price_Change: long (nullable = true)\n",
      " |-- Open_Price_Change: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "daily_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
