{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Model Deployment\n",
    "\n",
    "1. Load Model from S3\n",
    "2. Create Dataframe from structured streaming from Kinesis in 10 min intervals\n",
    "3. Make predictions\n",
    "4. Log predictions to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Initialize ####################################\n",
    "\n",
    "# Basic\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import date, datetime\n",
    "import boto3\n",
    "import boto3.s3\n",
    "import os.path\n",
    "import sys\n",
    "import io\n",
    "import warnings\n",
    "\n",
    "# Pipeline\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "\n",
    "# Feature Engineering\n",
    "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,\n",
    "                                Tokenizer,StopWordsRemover, CountVectorizer,IDF,StringIndexer, HashingTF)\n",
    "from pyspark.sql.functions import length\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import StringType\n",
    "import preprocessor as p\n",
    "from pyspark.sql.functions import dayofyear, concat_ws, collect_list, countDistinct\n",
    "from pyspark.sql.types import *\n",
    "# Models\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Streaming\n",
    "from pyspark.streaming.kinesis import KinesisUtils, InitialPositionInStream\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('nlp').getOrCreate()\n",
    "\n",
    "\n",
    "# Database Setup\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect\n",
    "from sqlalchemy import MetaData\n",
    "from sqlalchemy import Table\n",
    "from sqlalchemy import Column\n",
    "from sqlalchemy import Integer, String, DateTime, Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['aws', 's3', 'cp', 's3://brandyn-twitter-sentiment-analysis/Models/Daily_Stock_Prediction_latest/', './Models/Daily_Stock_Prediction_latest', '--recursive'], returncode=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the Model\n",
    "subprocess.run(['aws', 's3','cp','s3://brandyn-twitter-sentiment-analysis/Models/Daily_Stock_Prediction_latest/','./Models/Daily_Stock_Prediction_latest','--recursive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deserialize Model\n",
    "model = PipelineModel.load('./Models/Daily_Stock_Prediction_latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# Bring in Data ###############################\n",
    "\n",
    "#### Twitter ####\n",
    "# Create Schema\n",
    "twitterSchema = StructType() \\\n",
    "            .add(\"created_at\", TimestampType()) \\\n",
    "            .add(\"text\", StringType()) \\\n",
    "            .add(\"user_followers_count\", LongType()) \\\n",
    "            .add(\"user_name\", StringType()) \\\n",
    "            .add(\"Company\", StringType())\n",
    "\n",
    "# Create Dataframe\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
