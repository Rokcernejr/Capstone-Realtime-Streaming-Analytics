{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Initialize ####################################\n",
    "\n",
    "# Basic\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "# Spark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "\n",
    "from pyspark.sql.functions import desc, col, window\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to read from S3 and use structured streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To bypass the no s3 file system installed.\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.amazonaws:aws-java-sdk:1.10.34,org.apache.hadoop:hadoop-aws:2.6.0 pyspark-shell'\n",
    "\n",
    "APP_NAME = \"Test\"\n",
    "SPARK_URL = \"local[*]\"\n",
    "\n",
    "spark = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()\n",
    "sqlContext = SQLContext(spark)\n",
    "\n",
    "hadoopConf = spark._jsc.hadoopConfiguration()\n",
    "myAccessKey = os.environ['AWS_ACCESS_KEY_ID'] \n",
    "mySecretKey = os.environ['AWS_SECRET_ACCESS_KEY']\n",
    "hadoopConf.set(\"fs.s3.impl\", \"org.apache.hadoop.fs.s3native.NativeS3FileSystem\")\n",
    "hadoopConf.set(\"fs.s3.awsAccessKeyId\", myAccessKey)\n",
    "hadoopConf.set(\"fs.s3.awsSecretAccessKey\", mySecretKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Twitter #### Static Read\n",
    "inputPath = \"s3://brandyn-twitter-sentiment-analysis/Twitter2018/*/*/*\"\n",
    "\n",
    "# Create Schema\n",
    "twitterSchema = StructType() \\\n",
    "            .add(\"created_at\", StringType()) \\\n",
    "            .add(\"id_str\", StringType()) \\\n",
    "            .add(\"text\", StringType()) \\\n",
    "            .add(\"quote_count\", StringType()) \\\n",
    "            .add(\"reply_count\", StringType()) \\\n",
    "            .add(\"retweet_count\", StringType()) \\\n",
    "            .add(\"favorite_count\", StringType()) \\\n",
    "            .add(\"retweeted\", StringType()) \\\n",
    "            .add(\"lang\", StringType()) \\\n",
    "            .add(\"user_name\", StringType()) \\\n",
    "            .add(\"user_followers_count\", StringType()) \\\n",
    "            .add(\"user_statuses_count\", StringType()) \\\n",
    "            .add(\"user_screen_name\", StringType()) \\\n",
    "            .add(\"Company\", StringType())\n",
    "\n",
    "# Create Dataframe\n",
    "testDf = spark.read.schema(twitterSchema).json(inputPath, multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+--------------------+-----------+-----------+-------------+--------------+---------+----+--------------------+--------------------+-------------------+----------------+-----------------+\n",
      "|          created_at|            id_str|                text|quote_count|reply_count|retweet_count|favorite_count|retweeted|lang|           user_name|user_followers_count|user_statuses_count|user_screen_name|          Company|\n",
      "+--------------------+------------------+--------------------+-----------+-----------+-------------+--------------+---------+----+--------------------+--------------------+-------------------+----------------+-----------------+\n",
      "|Fri May 18 16:18:...|997511693264719872|RT @NOD008: I've ...|          0|          0|            0|             0|    false|  en|       Hugh R Calder|                  65|               3862|     DrHugh2thDr|         [\"TSLA\"]|\n",
      "|Fri May 18 16:12:...|997510337673871360|Isn't Elon suppos...|          0|          0|            0|             0|    false|  en|          Tim Knight|               18822|              28248|     SlopeOfHope|         [\"TSLA\"]|\n",
      "|Fri May 18 16:28:...|997514218269065216|Here are the top ...|          0|          0|            0|             0|    false|  en|             The Fly|               18189|              81197|      theflynews|            [\"V\"]|\n",
      "|Fri May 18 17:57:...|997536730961018880|$GOOGL WSJ: Googl...|          0|          0|            0|             0|    false|  en|       StockNews.com|                 883|             163970| stocknewsdotcom| [\"GOOG\",\"GOOGL\"]|\n",
      "|Fri May 18 16:33:...|997515536228667392|Started small wit...|          0|          0|            0|             0|    false|  en|       Travis Howard|                1377|              16340|   TravisHoward5|    [\"BA\",\"BABA\"]|\n",
      "|Fri May 18 16:48:...|997519407466168320|$XOM 2018-05-18 m...|          0|          0|            0|             0|    false|  en|                FinX|                   7|              24465|         FinX_io|          [\"XOM\"]|\n",
      "|Fri May 18 16:23:...|997512956207337472|$TSLA STC half my...|          0|          0|            0|             0|    false|  en|       labombagrande|                  29|                590|   labombagrande|         [\"TSLA\"]|\n",
      "|Fri May 18 16:59:...|997522050653851648|Three Corner Glob...|          0|          0|            0|             0|    false|  en|Money Making Arti...|                  17|               9347|    mmahotstuff1|            [\"C\"]|\n",
      "|Fri May 18 17:26:...|997528861423427584|$WFC Wells Fargo ...|          0|          0|            0|             0|    false|  en|          StockTexts|                 557|             153161|      StockTexts|          [\"WFC\"]|\n",
      "|Fri May 18 19:20:...|997557477075030019|Spark Investment ...|          0|          0|            0|             0|    false|  en|         HuronReport|                  33|              12542|     huronreport|          [\"JNJ\"]|\n",
      "|Fri May 18 16:07:...|997509042477129731|RT @TommyThornton...|          0|          0|            0|             0|    false|  en|     David Bergerson|                 123|              19603|      bergie1393|         [\"TSLA\"]|\n",
      "|Fri May 18 18:13:...|997540620938948609|5.18.18 Elliott W...|          0|          0|            0|             0|    false|  en|          Ted Aguhob|                1592|              33097|      wavegenius|[\"BA\",\"V\",\"BABA\"]|\n",
      "|Fri May 18 17:10:...|997524912943312896|Hutchinson Capita...|          0|          0|            0|             0|    false|  en|   The Norman Weekly|                  11|               6301|    normanweekly|          [\"XOM\"]|\n",
      "|Fri May 18 18:18:...|997541925065551873|$JPM getting into...|          0|          0|            0|             0|    false|  en| SmallCapReporter ðŸ“ˆ|                3669|               6272|      MrSmallCap|          [\"JPM\"]|\n",
      "|Fri May 18 19:00:...|997552407239446528|Fake event for $A...|          0|          0|            0|             0|    false|  en|                 yon|                   1|                 68| yon_yon_yon_yon|         [\"AAPL\"]|\n",
      "|Fri May 18 18:43:...|997548338328293376|Warren Averett As...|          0|          0|            0|             0|    false|  en|      WhatsOnThorold|                  19|              11213| whatsonthorold2|         [\"INTC\"]|\n",
      "|Fri May 18 16:43:...|997518100030480384|American Asset Ma...|          0|          0|            0|             0|    false|  en|         Utah Herald|                  14|              11992|      utahherald|           [\"GE\"]|\n",
      "|Fri May 18 17:52:...|997535474603515905|Frontier Investme...|          0|          0|            0|             0|    false|  en|           Herald KS|                  27|              13909|        heraldks|      [\"XOM\",\"C\"]|\n",
      "|Fri May 18 17:47:...|997534153523499008|https://t.co/uAca...|          0|          0|            0|             0|    false|  en|          Bilo Selhi|               24604|              79312| StocksThatDoubl|            [\"C\"]|\n",
      "|Fri May 18 18:28:...|997544475600842752|See why these ass...|          0|          0|            0|             0|    false|  en|             FinBuzz|                1152|             238481|   PortfolioBuzz|         [\"TSLA\"]|\n",
      "+--------------------+------------------+--------------------+-----------+-----------+-------------+--------------+---------+----+--------------------+--------------------+-------------------+----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Streaming Input Dataframe\n",
    "from pyspark.streaming import StreamingContext\n",
    "streamingInputDF = (\n",
    "  spark\n",
    "    .readStream                       \n",
    "    .schema(twitterSchema)               # Set the schema of the JSON data\n",
    "    .option(\"maxFilesPerTrigger\", 1)  # Treat a sequence of files as a stream by picking one file at a time\n",
    "    .json(inputPath)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create STreaming dataframe\n",
    "streamingWindowDF = streamingInputDF \\\n",
    "    .select('user_name') \\\n",
    "    .groupBy(streamingInputDF.user_name) \\\n",
    "    .count() \\\n",
    "    .sort(desc('count'))\n",
    "\n",
    "# Is this Streaming?\n",
    "streamingWindowDF.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now start the engine\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"2\")  # keep the size of shuffles small\n",
    "\n",
    "# Write stream to an in memroy table called \n",
    "query = (\n",
    "  streamingWindowDF\n",
    "    .writeStream\n",
    "    .format(\"memory\")       \n",
    "    .queryName(\"tweets\")     # counts = name of the in-memory table\n",
    "    .outputMode(\"complete\")  # complete = all the counts should be in the table\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|          user_name|count|\n",
      "+-------------------+-----+\n",
      "|         Bibey Post|    3|\n",
      "|        Utah Herald|    2|\n",
      "|         StockTexts|    2|\n",
      "|               FinX|    1|\n",
      "|          Herald KS|    1|\n",
      "|           KL Daily|    1|\n",
      "|                yon|    1|\n",
      "|           HFTAlert|    1|\n",
      "|          Mr. Rigid|    1|\n",
      "|         Bilo Selhi|    1|\n",
      "|        Key Gazette|    1|\n",
      "|  Clark Joseph Kent|    1|\n",
      "|      Travis Howard|    1|\n",
      "|  The Norman Weekly|    1|\n",
      "|            The Fly|    1|\n",
      "|     The Lincolnian|    1|\n",
      "|        HuronReport|    1|\n",
      "|    David Bergerson|    1|\n",
      "|Chaffey Breeze News|    1|\n",
      "|      The San Times|    1|\n",
      "+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------------+-----+\n",
      "|          user_name|count|\n",
      "+-------------------+-----+\n",
      "|         Bibey Post|    3|\n",
      "|        Utah Herald|    2|\n",
      "|         StockTexts|    2|\n",
      "|               FinX|    1|\n",
      "|          Herald KS|    1|\n",
      "|           KL Daily|    1|\n",
      "|                yon|    1|\n",
      "|           HFTAlert|    1|\n",
      "|          Mr. Rigid|    1|\n",
      "|         Bilo Selhi|    1|\n",
      "|        Key Gazette|    1|\n",
      "|  Clark Joseph Kent|    1|\n",
      "|      Travis Howard|    1|\n",
      "|  The Norman Weekly|    1|\n",
      "|            The Fly|    1|\n",
      "|     The Lincolnian|    1|\n",
      "|        HuronReport|    1|\n",
      "|    David Bergerson|    1|\n",
      "|Chaffey Breeze News|    1|\n",
      "|      The San Times|    1|\n",
      "+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------------+-----+\n",
      "|          user_name|count|\n",
      "+-------------------+-----+\n",
      "|         Bibey Post|    3|\n",
      "|        Utah Herald|    2|\n",
      "|         StockTexts|    2|\n",
      "|               FinX|    1|\n",
      "|          Herald KS|    1|\n",
      "|           KL Daily|    1|\n",
      "|                yon|    1|\n",
      "|           HFTAlert|    1|\n",
      "|          Mr. Rigid|    1|\n",
      "|         Bilo Selhi|    1|\n",
      "|        Key Gazette|    1|\n",
      "|  Clark Joseph Kent|    1|\n",
      "|      Travis Howard|    1|\n",
      "|  The Norman Weekly|    1|\n",
      "|            The Fly|    1|\n",
      "|     The Lincolnian|    1|\n",
      "|        HuronReport|    1|\n",
      "|    David Bergerson|    1|\n",
      "|Chaffey Breeze News|    1|\n",
      "|      The San Times|    1|\n",
      "+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------------+-----+\n",
      "|          user_name|count|\n",
      "+-------------------+-----+\n",
      "|         Bibey Post|    3|\n",
      "|        Utah Herald|    2|\n",
      "|         StockTexts|    2|\n",
      "|               FinX|    1|\n",
      "|          Herald KS|    1|\n",
      "|           KL Daily|    1|\n",
      "|                yon|    1|\n",
      "|           HFTAlert|    1|\n",
      "|          Mr. Rigid|    1|\n",
      "|         Bilo Selhi|    1|\n",
      "|        Key Gazette|    1|\n",
      "|  Clark Joseph Kent|    1|\n",
      "|      Travis Howard|    1|\n",
      "|  The Norman Weekly|    1|\n",
      "|            The Fly|    1|\n",
      "|     The Lincolnian|    1|\n",
      "|        HuronReport|    1|\n",
      "|    David Bergerson|    1|\n",
      "|Chaffey Breeze News|    1|\n",
      "|      The San Times|    1|\n",
      "+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------------+-----+\n",
      "|          user_name|count|\n",
      "+-------------------+-----+\n",
      "|         Bibey Post|    3|\n",
      "|        Utah Herald|    2|\n",
      "|         StockTexts|    2|\n",
      "|               FinX|    1|\n",
      "|          Herald KS|    1|\n",
      "|           KL Daily|    1|\n",
      "|                yon|    1|\n",
      "|           HFTAlert|    1|\n",
      "|          Mr. Rigid|    1|\n",
      "|         Bilo Selhi|    1|\n",
      "|        Key Gazette|    1|\n",
      "|  Clark Joseph Kent|    1|\n",
      "|      Travis Howard|    1|\n",
      "|  The Norman Weekly|    1|\n",
      "|            The Fly|    1|\n",
      "|     The Lincolnian|    1|\n",
      "|        HuronReport|    1|\n",
      "|    David Bergerson|    1|\n",
      "|Chaffey Breeze News|    1|\n",
      "|      The San Times|    1|\n",
      "+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------------+-----+\n",
      "|          user_name|count|\n",
      "+-------------------+-----+\n",
      "|         Bibey Post|    3|\n",
      "|        Utah Herald|    2|\n",
      "|         StockTexts|    2|\n",
      "|               FinX|    1|\n",
      "|          Herald KS|    1|\n",
      "|           KL Daily|    1|\n",
      "|                yon|    1|\n",
      "|           HFTAlert|    1|\n",
      "|          Mr. Rigid|    1|\n",
      "|         Bilo Selhi|    1|\n",
      "|        Key Gazette|    1|\n",
      "|  Clark Joseph Kent|    1|\n",
      "|      Travis Howard|    1|\n",
      "|  The Norman Weekly|    1|\n",
      "|            The Fly|    1|\n",
      "|     The Lincolnian|    1|\n",
      "|        HuronReport|    1|\n",
      "|    David Bergerson|    1|\n",
      "|Chaffey Breeze News|    1|\n",
      "|      The San Times|    1|\n",
      "+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2038a74aeaf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"select * from tweets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# let the query run for a bit to insure there is data in the recent progress structure.\n",
    "time.sleep(4)\n",
    "\n",
    "# Monitor the progress of the query. The last table should be identical to the static query.\n",
    "while True:\n",
    "    spark.sql(\"select * from tweets\").show(20)\n",
    "    time.sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
