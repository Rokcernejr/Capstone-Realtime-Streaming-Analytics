{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Companies Daily Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Initialize ###################\n",
    "\n",
    "# Basics\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import boto3\n",
    "import io\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "import spacy\n",
    "spacy.load('en')\n",
    "from nltk.corpus import stopwords\n",
    "import preprocessor as p\n",
    "\n",
    "# Model Infrastructure\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.pipeline import make_pipeline, Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn import metrics\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier, XGBRegressor\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Bring In Data #######################\n",
    "#Setup Mongo and create the database and collection\n",
    "User = os.environ['MONGODB_USER']\n",
    "password = os.environ['MONGODB_PASS']\n",
    "IP = os.environ['IP']\n",
    "\n",
    "client = MongoClient(IP, username=User, password=password)\n",
    "db = client['stock_tweets']\n",
    "\n",
    "#Grab references\n",
    "twitter_coll_reference = db.twitter\n",
    "iex_coll_reference = db.iex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Execution time: 31.369733095169067 seconds ---\n"
     ]
    }
   ],
   "source": [
    "###################### Build Twitter Data Frames #####################\n",
    "\n",
    "start_time = time.time()\n",
    "# Create Data Frame\n",
    "twitter_data = pd.DataFrame(list(twitter_coll_reference.find()))\n",
    "\n",
    "# Need to convert the created_at to a time stamp and set to index\n",
    "twitter_data.index=pd.to_datetime(twitter_data['created_at'])\n",
    "\n",
    "# Delimited the Company List into separate rows\n",
    "delimited_twitter_data=[]\n",
    "\n",
    "for item in twitter_data.itertuples():\n",
    "    #twitter_dict={}\n",
    "    for company in item[1]:\n",
    "        twitter_dict={}\n",
    "        twitter_dict['created_at']=item[0]\n",
    "        twitter_dict['company']=company\n",
    "        twitter_dict['text']=item[11]\n",
    "        twitter_dict['user_followers_count']=item[12]\n",
    "        twitter_dict['user_name']=item[13]\n",
    "        twitter_dict['user_statuses_count']=item[15]\n",
    "        delimited_twitter_data.append(twitter_dict)\n",
    "\n",
    "delimited_twitter_df = pd.DataFrame(delimited_twitter_data) \n",
    "delimited_twitter_df.set_index('created_at', inplace=True)\n",
    "\n",
    "# Create hourly data frame\n",
    "twitter_delimited_hourly = delimited_twitter_df.groupby([pd.Grouper(freq=\"D\"), 'company']).count()['text'].to_frame()\n",
    "twitter_delimited_hourly.columns = ['Number_of_Tweets']\n",
    "\n",
    "# Concatenate the text with a space to not combine words.\n",
    "twitter_delimited_hourly['text']=delimited_twitter_df.groupby([pd.Grouper(freq=\"D\"), 'company'])['text'].apply(lambda x: ' '.join(x))\n",
    "# Number of Users\n",
    "twitter_delimited_hourly['Number_of_Users'] = delimited_twitter_df.groupby([pd.Grouper(freq=\"D\"), 'company'])['user_name'].nunique()\n",
    "\n",
    "# Rename Index\n",
    "twitter_delimited_hourly = twitter_delimited_hourly.reindex(twitter_delimited_hourly.index.rename(['Time', 'Company']))\n",
    "\n",
    "print(\"-- Execution time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Execution time: 10.226880311965942 seconds ---\n"
     ]
    }
   ],
   "source": [
    "##################### Build Stock Data Frames ###########################\n",
    "start_time = time.time()\n",
    "\n",
    "stock_data = pd.DataFrame(list(iex_coll_reference.find()))\n",
    "\n",
    "# Need to convert the created_at to a time stamp\n",
    "stock_data.index=pd.to_datetime(stock_data['latestUpdate'])\n",
    "stock_data['latestUpdate'] = pd.to_datetime(stock_data['latestUpdate'])\n",
    "#Group By hourly and stock price\n",
    "# Need to get the first stock price in teh hour, and then the last to take the difference to see how much change.\n",
    "stock_delimited_hourly = stock_data.sort_values('latestUpdate').groupby([pd.Grouper(freq=\"D\"), 'Ticker']).first()['latestPrice'].to_frame()\n",
    "stock_delimited_hourly.columns = ['First_Price']\n",
    "stock_delimited_hourly['Last_Price'] = stock_data.sort_values('latestUpdate').groupby([pd.Grouper(freq=\"D\"), 'Ticker']).last()['latestPrice']\n",
    "\n",
    "# Then need to take the difference and turn into a percentage.\n",
    "stock_delimited_hourly['Price_Percent_Change'] = ((stock_delimited_hourly['Last_Price'] \n",
    "                                                   - stock_delimited_hourly['First_Price'])/stock_delimited_hourly['First_Price'])*100\n",
    "\n",
    "# Need to also show Percent from open price\n",
    "stock_delimited_hourly['Open_Price'] = stock_data.groupby([pd.Grouper(freq=\"D\"), 'Ticker'])['open'].mean()\n",
    "stock_delimited_hourly['Price_Percent_Open'] = ((stock_delimited_hourly['Last_Price'] \n",
    "                                                 - stock_delimited_hourly['Open_Price'])/stock_delimited_hourly['Open_Price'])*100\n",
    "\n",
    "# Also include mean volume\n",
    "stock_delimited_hourly['Mean_Volume'] = stock_data.groupby([pd.Grouper(freq=\"D\"), 'Ticker'])['latestVolume'].mean()\n",
    "\n",
    "# Classification Labels\n",
    "stock_delimited_hourly['Price_Change'] = np.where(stock_delimited_hourly['Price_Percent_Change']>=0, 1, 0)\n",
    "stock_delimited_hourly['Open_Price_Change'] = np.where(stock_delimited_hourly['Price_Percent_Open']>=0, 1, 0)\n",
    "\n",
    "# Rename the Index\n",
    "stock_delimited_hourly = stock_delimited_hourly.reindex(stock_delimited_hourly.index.rename(['Time', 'Company']))\n",
    "print(\"-- Execution time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Company</th>\n",
       "      <th>Number_of_Tweets</th>\n",
       "      <th>text</th>\n",
       "      <th>Number_of_Users</th>\n",
       "      <th>First_Price</th>\n",
       "      <th>Last_Price</th>\n",
       "      <th>Price_Percent_Change</th>\n",
       "      <th>Open_Price</th>\n",
       "      <th>Price_Percent_Open</th>\n",
       "      <th>Mean_Volume</th>\n",
       "      <th>Price_Change</th>\n",
       "      <th>Open_Price_Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-03-12</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>275</td>\n",
       "      <td>Amazon hits $1600 $AMZN Americans reported one...</td>\n",
       "      <td>162</td>\n",
       "      <td>1600.745</td>\n",
       "      <td>1598.39</td>\n",
       "      <td>-0.147119</td>\n",
       "      <td>1592.600000</td>\n",
       "      <td>0.363556</td>\n",
       "      <td>4.376277e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-03-12</td>\n",
       "      <td>FB</td>\n",
       "      <td>128</td>\n",
       "      <td>RT @stockstreamtv: https://t.co/wpKWA7TkY5 // ...</td>\n",
       "      <td>74</td>\n",
       "      <td>185.460</td>\n",
       "      <td>184.76</td>\n",
       "      <td>-0.377440</td>\n",
       "      <td>185.260000</td>\n",
       "      <td>-0.269891</td>\n",
       "      <td>1.253817e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-03-12</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>153</td>\n",
       "      <td>$TSLA so nice so obvious... $TSLA bears just g...</td>\n",
       "      <td>125</td>\n",
       "      <td>344.645</td>\n",
       "      <td>345.51</td>\n",
       "      <td>0.250983</td>\n",
       "      <td>328.900000</td>\n",
       "      <td>5.050167</td>\n",
       "      <td>7.304020e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018-03-13</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>531</td>\n",
       "      <td>Commented on $EXPE $FB $MS $AMZN https://t.co/...</td>\n",
       "      <td>347</td>\n",
       "      <td>1614.100</td>\n",
       "      <td>1588.64</td>\n",
       "      <td>-1.577350</td>\n",
       "      <td>1617.326229</td>\n",
       "      <td>-1.773682</td>\n",
       "      <td>3.913528e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2018-03-13</td>\n",
       "      <td>FB</td>\n",
       "      <td>318</td>\n",
       "      <td>Trade: Short $XLV\\n\\nhttps://t.co/kQ3uA7vvbT  ...</td>\n",
       "      <td>166</td>\n",
       "      <td>185.260</td>\n",
       "      <td>181.96</td>\n",
       "      <td>-1.781280</td>\n",
       "      <td>185.497943</td>\n",
       "      <td>-1.907268</td>\n",
       "      <td>9.869588e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time Company  Number_of_Tweets  \\\n",
       "1  2018-03-12    AMZN               275   \n",
       "8  2018-03-12      FB               128   \n",
       "20 2018-03-12    TSLA               153   \n",
       "28 2018-03-13    AMZN               531   \n",
       "35 2018-03-13      FB               318   \n",
       "\n",
       "                                                 text  Number_of_Users  \\\n",
       "1   Amazon hits $1600 $AMZN Americans reported one...              162   \n",
       "8   RT @stockstreamtv: https://t.co/wpKWA7TkY5 // ...               74   \n",
       "20  $TSLA so nice so obvious... $TSLA bears just g...              125   \n",
       "28  Commented on $EXPE $FB $MS $AMZN https://t.co/...              347   \n",
       "35  Trade: Short $XLV\\n\\nhttps://t.co/kQ3uA7vvbT  ...              166   \n",
       "\n",
       "    First_Price  Last_Price  Price_Percent_Change   Open_Price  \\\n",
       "1      1600.745     1598.39             -0.147119  1592.600000   \n",
       "8       185.460      184.76             -0.377440   185.260000   \n",
       "20      344.645      345.51              0.250983   328.900000   \n",
       "28     1614.100     1588.64             -1.577350  1617.326229   \n",
       "35      185.260      181.96             -1.781280   185.497943   \n",
       "\n",
       "    Price_Percent_Open   Mean_Volume  Price_Change  Open_Price_Change  \n",
       "1             0.363556  4.376277e+06             0                  1  \n",
       "8            -0.269891  1.253817e+07             0                  0  \n",
       "20            5.050167  7.304020e+06             1                  1  \n",
       "28           -1.773682  3.913528e+06             0                  0  \n",
       "35           -1.907268  9.869588e+06             0                  0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################### Combine Data Frames ##############################\n",
    "daily_df = pd.concat([twitter_delimited_hourly, stock_delimited_hourly], axis=1, join='inner')\n",
    "\n",
    "# To flatten after combined everything. \n",
    "daily_df.reset_index(inplace=True)\n",
    "daily_df = daily_df[((daily_df['Company']=='FB') | \n",
    "                     (daily_df['Company']=='TSLA') | \n",
    "                     (daily_df['Company']=='AMZN'))]\n",
    "daily_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Execution time: 1.8520677089691162 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Clean the Tweets\n",
    "p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.MENTION, p.OPT.RESERVED, p.OPT.EMOJI, p.OPT.HASHTAG)\n",
    "def preprocess_tweet(tweet):\n",
    "    return p.clean(tweet)\n",
    "\n",
    "# Clean the tweets, by removing special characters\n",
    "start_time = time.time()\n",
    "daily_df['Clean_text'] = daily_df['text'].apply(lambda x: preprocess_tweet(x))\n",
    "print(\"-- Execution time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Between Outcome and Features\n",
    "features = daily_df[['Company','Number_of_Tweets', 'Number_of_Users','Mean_Volume','Clean_text']]\n",
    "classification_price = daily_df['Price_Change']\n",
    "classification_open = daily_df['Open_Price_Change']\n",
    "regression_price = daily_df['Price_Percent_Change']\n",
    "regression_open = daily_df['Price_Percent_Open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_of_Tweets</th>\n",
       "      <th>Number_of_Users</th>\n",
       "      <th>Mean_Volume</th>\n",
       "      <th>Clean_text</th>\n",
       "      <th>Company_FB</th>\n",
       "      <th>Company_TSLA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>275</td>\n",
       "      <td>162</td>\n",
       "      <td>4.376277e+06</td>\n",
       "      <td>Amazon hits $1600 $AMZN Americans reported one...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>128</td>\n",
       "      <td>74</td>\n",
       "      <td>1.253817e+07</td>\n",
       "      <td>: // $FB $AMZN $AAPL $NFLX $GOOGL $MSFT $TWTR ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>153</td>\n",
       "      <td>125</td>\n",
       "      <td>7.304020e+06</td>\n",
       "      <td>$TSLA so nice so obvious... $TSLA bears just g...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>531</td>\n",
       "      <td>347</td>\n",
       "      <td>3.913528e+06</td>\n",
       "      <td>Commented on $EXPE $FB $MS $AMZN RT : Discreti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>318</td>\n",
       "      <td>166</td>\n",
       "      <td>9.869588e+06</td>\n",
       "      <td>Trade: Short $XLV Positions: long $FB $SPY $XL...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number_of_Tweets  Number_of_Users   Mean_Volume  \\\n",
       "1                275              162  4.376277e+06   \n",
       "8                128               74  1.253817e+07   \n",
       "20               153              125  7.304020e+06   \n",
       "28               531              347  3.913528e+06   \n",
       "35               318              166  9.869588e+06   \n",
       "\n",
       "                                           Clean_text  Company_FB  \\\n",
       "1   Amazon hits $1600 $AMZN Americans reported one...           0   \n",
       "8   : // $FB $AMZN $AAPL $NFLX $GOOGL $MSFT $TWTR ...           1   \n",
       "20  $TSLA so nice so obvious... $TSLA bears just g...           0   \n",
       "28  Commented on $EXPE $FB $MS $AMZN RT : Discreti...           0   \n",
       "35  Trade: Short $XLV Positions: long $FB $SPY $XL...           1   \n",
       "\n",
       "    Company_TSLA  \n",
       "1              0  \n",
       "8              0  \n",
       "20             1  \n",
       "28             0  \n",
       "35             0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Want to leverage the Company name so need to create dummy variables. \n",
    "cat_feats = ['Company']\n",
    "features = pd.get_dummies(features, columns=cat_feats, drop_first=True)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will create a class to handle this. \n",
    "class DataSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, features):\n",
    "        if self.key=='text':\n",
    "            return features['Clean_text']\n",
    "        else:\n",
    "            return features.loc[:, features.columns != 'Clean_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    76\n",
       "1    56\n",
       "Name: Price_Change, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check is Data is imbalanced\n",
    "daily_df['Price_Change'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Data to avoid Leakage\n",
    "#splitting into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,classification_price,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing Finished. Number of features: 51475\n",
      "Explained Variance: 0.9966214902817914\n",
      "-- Execution time: 8.706959247589111 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Check to see how much variance is being explained\n",
    "\n",
    "X = X_train['Clean_text']\n",
    "\n",
    "start_time = time.time()\n",
    "# Create lemmatizer using spacy\n",
    "lemmatizer = spacy.lang.en.English()\n",
    "\n",
    "def custom_tokenizer(doc):\n",
    "    tokens = lemmatizer(doc)\n",
    "    return([token.lemma_ for token in tokens if not token.is_punct])\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, stop_words='english',\n",
    "                             lowercase=True, use_idf=True, max_df=0.5, \n",
    "                             min_df=2, norm='l2', smooth_idf=True, ngram_range=(1, 2))\n",
    "\n",
    "tweets_tfidf = vectorizer.fit_transform(X)\n",
    "print(\"Vectorizing Finished. Number of features: %d\" % tweets_tfidf.get_shape()[1])\n",
    "pipe = Pipeline(steps=[\n",
    "                 ('svd', TruncatedSVD(100)),\n",
    "                 ('norm',Normalizer(copy=False))\n",
    "                       ])\n",
    "\n",
    "pipe.fit_transform(tweets_tfidf)\n",
    "print(\"Explained Variance: \" + str(pipe.get_params()['svd'].explained_variance_ratio_.sum()))\n",
    "print(\"-- Execution time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Execution time: 20.969570875167847 seconds ---\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.25      0.57      0.35         7\n",
      "          1       0.73      0.40      0.52        20\n",
      "\n",
      "avg / total       0.60      0.44      0.47        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####### Logistic Regression ############\n",
    "\n",
    "start_time = time.time()\n",
    "# Create lemmatizer using spacy\n",
    "lemmatizer = spacy.lang.en.English()\n",
    "\n",
    "# Define Model\n",
    "lr_model = LogisticRegression(n_jobs=5)\n",
    "\n",
    "# Define custom Tokenizer\n",
    "def custom_tokenizer(doc):\n",
    "    tokens = lemmatizer(doc)\n",
    "    return([token.lemma_ for token in tokens if not token.is_punct])\n",
    "\n",
    "# Define Vectorizer\n",
    "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, stop_words='english',\n",
    "                             lowercase=True, use_idf=True, max_df=2,\n",
    "                             min_df=2, norm='l2', smooth_idf=True, ngram_range=(1, 2))\n",
    "\n",
    "# Define Pipeline and Feature Union\n",
    "pipeline = Pipeline([\n",
    "    # Use Feature Union to combine features from the Tweet and other features gathered\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "            # Pipeline for text\n",
    "            ('tweet', Pipeline([\n",
    "                ('selector', DataSelector(key='text')),\n",
    "                ('vectidf', vectorizer),\n",
    "                ('svd', TruncatedSVD(100)),\n",
    "                ('norm',Normalizer(copy=False))\n",
    "                                \n",
    "            ])),\n",
    "            \n",
    "            # Pipeline for getting other features\n",
    "            ('other', Pipeline([\n",
    "                ('seclector', DataSelector(key='other'))\n",
    "             ])),\n",
    "        ],\n",
    "                       \n",
    "    )),\n",
    "    # Use Logistic Regression Classifier\n",
    "    ('lr', lr_model)\n",
    "])\n",
    "\n",
    "# Grid Search\n",
    "parameters = {\n",
    "                'lr__penalty':['l1'],\n",
    "                'lr__C':[10],\n",
    "                'lr__class_weight':['balanced'],\n",
    "                #'lr__solver':['newton-cg'],\n",
    "                'union__transformer_weights':[{'tweet':0.7, 'other':0.3}]\n",
    "               \n",
    "              }\n",
    "\n",
    "grid = GridSearchCV(pipeline, parameters, scoring='f1', cv=2, verbose=0, n_jobs=10)\n",
    "\n",
    "# Fit the grid\n",
    "grid.fit(X_train, y_train)\n",
    "# Predictions\n",
    "y = grid.predict(X_test)\n",
    "print(\"-- Execution time: %s seconds ---\" % (time.time() - start_time))\n",
    "print(classification_report(y, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
